{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "Import_library"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import structlog\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "Path_Set"
    ]
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Tamil_dataset\"\n",
    "JSON_PATH = \"pyt\\hon_files1/data1.json\"\n",
    "json_path1 = \"python_files1/data_2_new_2.json\"\n",
    "SAMPLE_RATE = 16000\n",
    "TRACK_DURATION = 1 \n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "DATA_PATH = \"python_files1/data1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "Predict"
    ]
   },
   "outputs": [],
   "source": [
    "def predict_1(model, X):\n",
    "    \n",
    "    X = X[np.newaxis, ...]\n",
    "\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    if predicted_index == 0:\n",
    "        print(\" Your are affecting Dysarthria \")\n",
    "    if predicted_index == 1:\n",
    "        print(\" Your are voice is Normal Level \")\n",
    "    if predicted_index == 2:\n",
    "        print(\" Your are voice Not_audiable\")\n",
    "    if predicted_index == 3:\n",
    "        print(\" Your are affectings stuttering \")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "Convert_audio_into_MFFC_save_json_file"
    ]
   },
   "outputs": [],
   "source": [
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        if dirpath is not dataset_path:\n",
    "            \n",
    "            semantic_label = dirpath.split(\"\\\\\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            for f in filenames:\n",
    " \n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                if len(signal) >= SAMPLE_RATE:\n",
    "                    signals = signal\n",
    "                else:\n",
    "                    signal = np.pad(\n",
    "                        signal,\n",
    "                        pad_width=(SAMPLE_RATE - len(signal), 0),\n",
    "                        mode=\"constant\",\n",
    "                        constant_values=(0, 0),\n",
    "                    )\n",
    "\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T                   \n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "Load_data"
    ]
   },
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "Graph_plot"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "\n",
    "    fig, axs = plt.subplots(1)\n",
    "    axs.plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs.plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs.set_ylabel(\"Accuracy\")\n",
    "    axs.legend(loc=\"lower right\")\n",
    "    axs.set_title(\"Accuracy eval\")\n",
    "    plt.show()\n",
    "    fig, axs = plt.subplots(1)\n",
    "    axs.plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs.plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs.set_ylabel(\"Error\")\n",
    "    axs.set_xlabel(\"Epoch\")\n",
    "    axs.legend(loc=\"upper right\")\n",
    "    axs.set_title(\"Error eval\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "Prepare_data_set"
    ]
   },
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, validation_size):\n",
    "\n",
    "\n",
    "    X, y = load_data(DATA_PATH)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    \n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "CNN_model_Build"
    ]
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) \n",
    "    \n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Dense(26, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "Predict_test_data"
    ]
   },
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    \n",
    "    X = X[np.newaxis, ...]\n",
    "\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "MFCC_fuction_call_and",
     "_main_function"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-11-3747e9cc121f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-3747e9cc121f>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    #save_mfcc(DATASET_PATH, JSON_PATH, num_segments=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "Prepare_data_function_call"
    ]
   },
   "outputs": [],
   "source": [
    "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.30, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "Model_built_call"
    ]
   },
   "outputs": [],
   "source": [
    "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    model = build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "Compile_model"
    ]
   },
   "outputs": [],
   "source": [
    "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "Fit_Model"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 4.8825 - accuracy: 0.0000e+ - ETA: 3s - loss: 4.5312 - accuracy: 0.0156   - ETA: 3s - loss: 4.2664 - accuracy: 0.00 - ETA: 4s - loss: 4.2302 - accuracy: 0.00 - ETA: 4s - loss: 4.0864 - accuracy: 0.00 - ETA: 3s - loss: 3.9550 - accuracy: 0.01 - ETA: 4s - loss: 3.8549 - accuracy: 0.02 - ETA: 4s - loss: 3.8319 - accuracy: 0.02 - ETA: 4s - loss: 3.7667 - accuracy: 0.02 - ETA: 4s - loss: 3.7029 - accuracy: 0.03 - ETA: 4s - loss: 3.5817 - accuracy: 0.05 - ETA: 4s - loss: 3.5109 - accuracy: 0.06 - ETA: 3s - loss: 3.4197 - accuracy: 0.07 - ETA: 3s - loss: 3.3246 - accuracy: 0.08 - ETA: 3s - loss: 3.2816 - accuracy: 0.09 - ETA: 3s - loss: 3.1732 - accuracy: 0.11 - ETA: 3s - loss: 3.0914 - accuracy: 0.12 - ETA: 3s - loss: 3.0547 - accuracy: 0.13 - ETA: 3s - loss: 2.9648 - accuracy: 0.15 - ETA: 3s - loss: 2.8865 - accuracy: 0.18 - ETA: 3s - loss: 2.8436 - accuracy: 0.19 - ETA: 3s - loss: 2.7768 - accuracy: 0.21 - ETA: 3s - loss: 2.7067 - accuracy: 0.23 - ETA: 3s - loss: 2.6811 - accuracy: 0.24 - ETA: 3s - loss: 2.6030 - accuracy: 0.26 - ETA: 2s - loss: 2.5402 - accuracy: 0.28 - ETA: 2s - loss: 2.5099 - accuracy: 0.29 - ETA: 2s - loss: 2.4809 - accuracy: 0.30 - ETA: 2s - loss: 2.4224 - accuracy: 0.32 - ETA: 2s - loss: 2.4054 - accuracy: 0.33 - ETA: 2s - loss: 2.3538 - accuracy: 0.34 - ETA: 2s - loss: 2.3055 - accuracy: 0.35 - ETA: 2s - loss: 2.2779 - accuracy: 0.36 - ETA: 2s - loss: 2.2323 - accuracy: 0.37 - ETA: 2s - loss: 2.2137 - accuracy: 0.38 - ETA: 2s - loss: 2.1713 - accuracy: 0.39 - ETA: 2s - loss: 2.1518 - accuracy: 0.40 - ETA: 2s - loss: 2.1139 - accuracy: 0.41 - ETA: 2s - loss: 2.0932 - accuracy: 0.41 - ETA: 1s - loss: 2.0558 - accuracy: 0.42 - ETA: 1s - loss: 2.0391 - accuracy: 0.43 - ETA: 1s - loss: 2.0063 - accuracy: 0.44 - ETA: 1s - loss: 1.9902 - accuracy: 0.44 - ETA: 1s - loss: 1.9577 - accuracy: 0.45 - ETA: 1s - loss: 1.9461 - accuracy: 0.45 - ETA: 1s - loss: 1.9114 - accuracy: 0.46 - ETA: 1s - loss: 1.8990 - accuracy: 0.47 - ETA: 1s - loss: 1.8797 - accuracy: 0.47 - ETA: 1s - loss: 1.8500 - accuracy: 0.48 - ETA: 1s - loss: 1.8205 - accuracy: 0.49 - ETA: 1s - loss: 1.8088 - accuracy: 0.49 - ETA: 1s - loss: 1.7949 - accuracy: 0.49 - ETA: 1s - loss: 1.7740 - accuracy: 0.50 - ETA: 1s - loss: 1.7619 - accuracy: 0.50 - ETA: 1s - loss: 1.7477 - accuracy: 0.51 - ETA: 0s - loss: 1.7200 - accuracy: 0.51 - ETA: 0s - loss: 1.7074 - accuracy: 0.52 - ETA: 0s - loss: 1.6892 - accuracy: 0.52 - ETA: 0s - loss: 1.6667 - accuracy: 0.53 - ETA: 0s - loss: 1.6588 - accuracy: 0.53 - ETA: 0s - loss: 1.6495 - accuracy: 0.53 - ETA: 0s - loss: 1.6407 - accuracy: 0.54 - ETA: 0s - loss: 1.6191 - accuracy: 0.54 - ETA: 0s - loss: 1.6087 - accuracy: 0.54 - ETA: 0s - loss: 1.5875 - accuracy: 0.55 - ETA: 0s - loss: 1.5769 - accuracy: 0.55 - ETA: 0s - loss: 1.5682 - accuracy: 0.56 - ETA: 0s - loss: 1.5594 - accuracy: 0.56 - ETA: 0s - loss: 1.5504 - accuracy: 0.56 - ETA: 0s - loss: 1.5338 - accuracy: 0.57 - 5s 53ms/step - loss: 1.5338 - accuracy: 0.5703 - val_loss: 0.7384 - val_accuracy: 0.7457\n",
      "Epoch 2/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7562 - accuracy: 0.75 - ETA: 2s - loss: 0.7231 - accuracy: 0.78 - ETA: 3s - loss: 0.6897 - accuracy: 0.79 - ETA: 3s - loss: 0.6739 - accuracy: 0.80 - ETA: 4s - loss: 0.6532 - accuracy: 0.81 - ETA: 4s - loss: 0.6445 - accuracy: 0.80 - ETA: 4s - loss: 0.6326 - accuracy: 0.80 - ETA: 4s - loss: 0.6437 - accuracy: 0.79 - ETA: 4s - loss: 0.6232 - accuracy: 0.79 - ETA: 4s - loss: 0.6154 - accuracy: 0.79 - ETA: 4s - loss: 0.6044 - accuracy: 0.80 - ETA: 4s - loss: 0.5969 - accuracy: 0.80 - ETA: 4s - loss: 0.6119 - accuracy: 0.80 - ETA: 4s - loss: 0.6085 - accuracy: 0.80 - ETA: 3s - loss: 0.6069 - accuracy: 0.80 - ETA: 3s - loss: 0.6113 - accuracy: 0.80 - ETA: 3s - loss: 0.6001 - accuracy: 0.80 - ETA: 3s - loss: 0.5950 - accuracy: 0.80 - ETA: 3s - loss: 0.5981 - accuracy: 0.79 - ETA: 3s - loss: 0.5980 - accuracy: 0.80 - ETA: 3s - loss: 0.6038 - accuracy: 0.79 - ETA: 3s - loss: 0.6067 - accuracy: 0.79 - ETA: 3s - loss: 0.6057 - accuracy: 0.79 - ETA: 3s - loss: 0.5936 - accuracy: 0.79 - ETA: 3s - loss: 0.5968 - accuracy: 0.79 - ETA: 3s - loss: 0.5907 - accuracy: 0.79 - ETA: 3s - loss: 0.5861 - accuracy: 0.80 - ETA: 3s - loss: 0.5850 - accuracy: 0.80 - ETA: 3s - loss: 0.5796 - accuracy: 0.80 - ETA: 3s - loss: 0.5792 - accuracy: 0.80 - ETA: 3s - loss: 0.5809 - accuracy: 0.80 - ETA: 3s - loss: 0.5791 - accuracy: 0.80 - ETA: 2s - loss: 0.5755 - accuracy: 0.80 - ETA: 2s - loss: 0.5753 - accuracy: 0.80 - ETA: 2s - loss: 0.5726 - accuracy: 0.80 - ETA: 2s - loss: 0.5722 - accuracy: 0.80 - ETA: 2s - loss: 0.5752 - accuracy: 0.80 - ETA: 2s - loss: 0.5735 - accuracy: 0.80 - ETA: 2s - loss: 0.5723 - accuracy: 0.80 - ETA: 2s - loss: 0.5765 - accuracy: 0.80 - ETA: 2s - loss: 0.5748 - accuracy: 0.80 - ETA: 2s - loss: 0.5740 - accuracy: 0.80 - ETA: 2s - loss: 0.5722 - accuracy: 0.80 - ETA: 2s - loss: 0.5701 - accuracy: 0.80 - ETA: 2s - loss: 0.5632 - accuracy: 0.80 - ETA: 2s - loss: 0.5617 - accuracy: 0.80 - ETA: 2s - loss: 0.5573 - accuracy: 0.80 - ETA: 2s - loss: 0.5541 - accuracy: 0.81 - ETA: 1s - loss: 0.5551 - accuracy: 0.80 - ETA: 1s - loss: 0.5551 - accuracy: 0.80 - ETA: 1s - loss: 0.5505 - accuracy: 0.81 - ETA: 1s - loss: 0.5485 - accuracy: 0.81 - ETA: 1s - loss: 0.5464 - accuracy: 0.81 - ETA: 1s - loss: 0.5441 - accuracy: 0.81 - ETA: 1s - loss: 0.5466 - accuracy: 0.81 - ETA: 1s - loss: 0.5487 - accuracy: 0.81 - ETA: 1s - loss: 0.5467 - accuracy: 0.81 - ETA: 1s - loss: 0.5516 - accuracy: 0.81 - ETA: 1s - loss: 0.5515 - accuracy: 0.81 - ETA: 1s - loss: 0.5475 - accuracy: 0.81 - ETA: 1s - loss: 0.5447 - accuracy: 0.81 - ETA: 1s - loss: 0.5421 - accuracy: 0.81 - ETA: 1s - loss: 0.5469 - accuracy: 0.81 - ETA: 0s - loss: 0.5481 - accuracy: 0.81 - ETA: 0s - loss: 0.5470 - accuracy: 0.81 - ETA: 0s - loss: 0.5443 - accuracy: 0.81 - ETA: 0s - loss: 0.5421 - accuracy: 0.81 - ETA: 0s - loss: 0.5390 - accuracy: 0.81 - ETA: 0s - loss: 0.5360 - accuracy: 0.82 - ETA: 0s - loss: 0.5343 - accuracy: 0.82 - ETA: 0s - loss: 0.5331 - accuracy: 0.82 - ETA: 0s - loss: 0.5352 - accuracy: 0.81 - ETA: 0s - loss: 0.5341 - accuracy: 0.82 - ETA: 0s - loss: 0.5331 - accuracy: 0.82 - ETA: 0s - loss: 0.5316 - accuracy: 0.82 - ETA: 0s - loss: 0.5307 - accuracy: 0.82 - ETA: 0s - loss: 0.5288 - accuracy: 0.82 - ETA: 0s - loss: 0.5259 - accuracy: 0.82 - ETA: 0s - loss: 0.5263 - accuracy: 0.82 - 5s 53ms/step - loss: 0.5263 - accuracy: 0.8225 - val_loss: 0.3473 - val_accuracy: 0.8844\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.84 - ETA: 3s - loss: 0.3873 - accuracy: 0.84 - ETA: 3s - loss: 0.3869 - accuracy: 0.85 - ETA: 4s - loss: 0.4339 - accuracy: 0.82 - ETA: 4s - loss: 0.4307 - accuracy: 0.82 - ETA: 4s - loss: 0.4279 - accuracy: 0.82 - ETA: 4s - loss: 0.4182 - accuracy: 0.82 - ETA: 4s - loss: 0.4015 - accuracy: 0.83 - ETA: 4s - loss: 0.4214 - accuracy: 0.82 - ETA: 4s - loss: 0.4231 - accuracy: 0.82 - ETA: 4s - loss: 0.4170 - accuracy: 0.83 - ETA: 4s - loss: 0.4250 - accuracy: 0.83 - ETA: 4s - loss: 0.4163 - accuracy: 0.83 - ETA: 4s - loss: 0.4158 - accuracy: 0.83 - ETA: 4s - loss: 0.4110 - accuracy: 0.84 - ETA: 3s - loss: 0.4086 - accuracy: 0.84 - ETA: 3s - loss: 0.4095 - accuracy: 0.84 - ETA: 3s - loss: 0.4042 - accuracy: 0.84 - ETA: 3s - loss: 0.3958 - accuracy: 0.84 - ETA: 3s - loss: 0.3955 - accuracy: 0.84 - ETA: 3s - loss: 0.3902 - accuracy: 0.85 - ETA: 3s - loss: 0.3885 - accuracy: 0.85 - ETA: 3s - loss: 0.3919 - accuracy: 0.85 - ETA: 3s - loss: 0.3978 - accuracy: 0.84 - ETA: 3s - loss: 0.3981 - accuracy: 0.84 - ETA: 3s - loss: 0.3918 - accuracy: 0.85 - ETA: 3s - loss: 0.3942 - accuracy: 0.85 - ETA: 3s - loss: 0.3910 - accuracy: 0.85 - ETA: 3s - loss: 0.3878 - accuracy: 0.85 - ETA: 3s - loss: 0.3916 - accuracy: 0.85 - ETA: 3s - loss: 0.3890 - accuracy: 0.85 - ETA: 2s - loss: 0.3920 - accuracy: 0.85 - ETA: 2s - loss: 0.3920 - accuracy: 0.85 - ETA: 2s - loss: 0.3924 - accuracy: 0.85 - ETA: 2s - loss: 0.3902 - accuracy: 0.85 - ETA: 2s - loss: 0.3901 - accuracy: 0.85 - ETA: 2s - loss: 0.3887 - accuracy: 0.85 - ETA: 2s - loss: 0.3861 - accuracy: 0.86 - ETA: 2s - loss: 0.3854 - accuracy: 0.86 - ETA: 2s - loss: 0.3831 - accuracy: 0.86 - ETA: 2s - loss: 0.3808 - accuracy: 0.86 - ETA: 2s - loss: 0.3766 - accuracy: 0.86 - ETA: 2s - loss: 0.3798 - accuracy: 0.86 - ETA: 2s - loss: 0.3757 - accuracy: 0.86 - ETA: 2s - loss: 0.3807 - accuracy: 0.86 - ETA: 2s - loss: 0.3840 - accuracy: 0.86 - ETA: 1s - loss: 0.3843 - accuracy: 0.86 - ETA: 1s - loss: 0.3835 - accuracy: 0.86 - ETA: 1s - loss: 0.3807 - accuracy: 0.86 - ETA: 1s - loss: 0.3786 - accuracy: 0.86 - ETA: 1s - loss: 0.3796 - accuracy: 0.86 - ETA: 1s - loss: 0.3763 - accuracy: 0.86 - ETA: 1s - loss: 0.3730 - accuracy: 0.86 - ETA: 1s - loss: 0.3742 - accuracy: 0.86 - ETA: 1s - loss: 0.3732 - accuracy: 0.86 - ETA: 1s - loss: 0.3713 - accuracy: 0.86 - ETA: 1s - loss: 0.3723 - accuracy: 0.86 - ETA: 1s - loss: 0.3703 - accuracy: 0.87 - ETA: 0s - loss: 0.3716 - accuracy: 0.87 - ETA: 0s - loss: 0.3712 - accuracy: 0.87 - ETA: 0s - loss: 0.3728 - accuracy: 0.87 - ETA: 0s - loss: 0.3709 - accuracy: 0.87 - ETA: 0s - loss: 0.3680 - accuracy: 0.87 - ETA: 0s - loss: 0.3686 - accuracy: 0.87 - ETA: 0s - loss: 0.3691 - accuracy: 0.87 - ETA: 0s - loss: 0.3667 - accuracy: 0.87 - ETA: 0s - loss: 0.3661 - accuracy: 0.87 - ETA: 0s - loss: 0.3670 - accuracy: 0.87 - ETA: 0s - loss: 0.3657 - accuracy: 0.87 - ETA: 0s - loss: 0.3626 - accuracy: 0.87 - ETA: 0s - loss: 0.3669 - accuracy: 0.87 - 5s 50ms/step - loss: 0.3669 - accuracy: 0.8718 - val_loss: 0.2501 - val_accuracy: 0.9051\n",
      "Epoch 4/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.87 - ETA: 3s - loss: 0.3308 - accuracy: 0.87 - ETA: 3s - loss: 0.2855 - accuracy: 0.89 - ETA: 3s - loss: 0.2892 - accuracy: 0.89 - ETA: 3s - loss: 0.2859 - accuracy: 0.89 - ETA: 3s - loss: 0.2966 - accuracy: 0.89 - ETA: 3s - loss: 0.2907 - accuracy: 0.89 - ETA: 3s - loss: 0.3034 - accuracy: 0.88 - ETA: 3s - loss: 0.3033 - accuracy: 0.88 - ETA: 3s - loss: 0.3052 - accuracy: 0.87 - ETA: 3s - loss: 0.3054 - accuracy: 0.87 - ETA: 3s - loss: 0.3023 - accuracy: 0.88 - ETA: 3s - loss: 0.2968 - accuracy: 0.88 - ETA: 3s - loss: 0.3008 - accuracy: 0.88 - ETA: 3s - loss: 0.3083 - accuracy: 0.87 - ETA: 3s - loss: 0.3017 - accuracy: 0.88 - ETA: 3s - loss: 0.2983 - accuracy: 0.88 - ETA: 3s - loss: 0.2974 - accuracy: 0.88 - ETA: 3s - loss: 0.3008 - accuracy: 0.88 - ETA: 3s - loss: 0.2990 - accuracy: 0.88 - ETA: 3s - loss: 0.2974 - accuracy: 0.88 - ETA: 3s - loss: 0.2951 - accuracy: 0.89 - ETA: 3s - loss: 0.2990 - accuracy: 0.88 - ETA: 2s - loss: 0.3015 - accuracy: 0.88 - ETA: 2s - loss: 0.2972 - accuracy: 0.88 - ETA: 2s - loss: 0.3009 - accuracy: 0.88 - ETA: 2s - loss: 0.3004 - accuracy: 0.88 - ETA: 2s - loss: 0.2979 - accuracy: 0.88 - ETA: 2s - loss: 0.2967 - accuracy: 0.88 - ETA: 2s - loss: 0.2997 - accuracy: 0.88 - ETA: 2s - loss: 0.2979 - accuracy: 0.88 - ETA: 2s - loss: 0.2954 - accuracy: 0.88 - ETA: 2s - loss: 0.2952 - accuracy: 0.88 - ETA: 2s - loss: 0.2952 - accuracy: 0.88 - ETA: 2s - loss: 0.2912 - accuracy: 0.88 - ETA: 2s - loss: 0.2901 - accuracy: 0.89 - ETA: 2s - loss: 0.2868 - accuracy: 0.89 - ETA: 2s - loss: 0.2844 - accuracy: 0.89 - ETA: 1s - loss: 0.2862 - accuracy: 0.89 - ETA: 1s - loss: 0.2833 - accuracy: 0.89 - ETA: 1s - loss: 0.2858 - accuracy: 0.89 - ETA: 1s - loss: 0.2872 - accuracy: 0.89 - ETA: 1s - loss: 0.2851 - accuracy: 0.89 - ETA: 1s - loss: 0.2848 - accuracy: 0.89 - ETA: 1s - loss: 0.2864 - accuracy: 0.89 - ETA: 1s - loss: 0.2854 - accuracy: 0.89 - ETA: 1s - loss: 0.2852 - accuracy: 0.89 - ETA: 1s - loss: 0.2835 - accuracy: 0.89 - ETA: 1s - loss: 0.2823 - accuracy: 0.89 - ETA: 1s - loss: 0.2818 - accuracy: 0.89 - ETA: 1s - loss: 0.2813 - accuracy: 0.89 - ETA: 1s - loss: 0.2819 - accuracy: 0.89 - ETA: 1s - loss: 0.2858 - accuracy: 0.89 - ETA: 0s - loss: 0.2840 - accuracy: 0.89 - ETA: 0s - loss: 0.2872 - accuracy: 0.89 - ETA: 0s - loss: 0.2874 - accuracy: 0.89 - ETA: 0s - loss: 0.2881 - accuracy: 0.89 - ETA: 0s - loss: 0.2879 - accuracy: 0.89 - ETA: 0s - loss: 0.2882 - accuracy: 0.89 - ETA: 0s - loss: 0.2889 - accuracy: 0.89 - ETA: 0s - loss: 0.2881 - accuracy: 0.89 - ETA: 0s - loss: 0.2872 - accuracy: 0.89 - ETA: 0s - loss: 0.2862 - accuracy: 0.89 - ETA: 0s - loss: 0.2834 - accuracy: 0.89 - ETA: 0s - loss: 0.2850 - accuracy: 0.89 - ETA: 0s - loss: 0.2849 - accuracy: 0.89 - 5s 48ms/step - loss: 0.2845 - accuracy: 0.8937 - val_loss: 0.2175 - val_accuracy: 0.9161\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.87 - ETA: 2s - loss: 0.2304 - accuracy: 0.92 - ETA: 3s - loss: 0.2578 - accuracy: 0.89 - ETA: 3s - loss: 0.2410 - accuracy: 0.90 - ETA: 4s - loss: 0.2412 - accuracy: 0.90 - ETA: 4s - loss: 0.2151 - accuracy: 0.91 - ETA: 4s - loss: 0.2408 - accuracy: 0.90 - ETA: 4s - loss: 0.2709 - accuracy: 0.89 - ETA: 3s - loss: 0.2597 - accuracy: 0.90 - ETA: 4s - loss: 0.2685 - accuracy: 0.90 - ETA: 3s - loss: 0.2618 - accuracy: 0.90 - ETA: 3s - loss: 0.2581 - accuracy: 0.90 - ETA: 3s - loss: 0.2512 - accuracy: 0.90 - ETA: 3s - loss: 0.2476 - accuracy: 0.90 - ETA: 3s - loss: 0.2460 - accuracy: 0.90 - ETA: 3s - loss: 0.2459 - accuracy: 0.90 - ETA: 3s - loss: 0.2388 - accuracy: 0.91 - ETA: 3s - loss: 0.2389 - accuracy: 0.91 - ETA: 3s - loss: 0.2353 - accuracy: 0.91 - ETA: 3s - loss: 0.2353 - accuracy: 0.91 - ETA: 3s - loss: 0.2322 - accuracy: 0.91 - ETA: 3s - loss: 0.2268 - accuracy: 0.91 - ETA: 3s - loss: 0.2296 - accuracy: 0.91 - ETA: 2s - loss: 0.2281 - accuracy: 0.91 - ETA: 2s - loss: 0.2297 - accuracy: 0.91 - ETA: 2s - loss: 0.2297 - accuracy: 0.92 - ETA: 2s - loss: 0.2319 - accuracy: 0.91 - ETA: 2s - loss: 0.2312 - accuracy: 0.91 - ETA: 2s - loss: 0.2347 - accuracy: 0.91 - ETA: 2s - loss: 0.2363 - accuracy: 0.91 - ETA: 2s - loss: 0.2353 - accuracy: 0.91 - ETA: 2s - loss: 0.2361 - accuracy: 0.91 - ETA: 2s - loss: 0.2328 - accuracy: 0.91 - ETA: 2s - loss: 0.2390 - accuracy: 0.91 - ETA: 2s - loss: 0.2406 - accuracy: 0.91 - ETA: 2s - loss: 0.2405 - accuracy: 0.91 - ETA: 1s - loss: 0.2388 - accuracy: 0.91 - ETA: 1s - loss: 0.2402 - accuracy: 0.91 - ETA: 1s - loss: 0.2386 - accuracy: 0.91 - ETA: 1s - loss: 0.2435 - accuracy: 0.91 - ETA: 1s - loss: 0.2410 - accuracy: 0.91 - ETA: 1s - loss: 0.2416 - accuracy: 0.91 - ETA: 1s - loss: 0.2414 - accuracy: 0.91 - ETA: 1s - loss: 0.2413 - accuracy: 0.91 - ETA: 1s - loss: 0.2432 - accuracy: 0.91 - ETA: 1s - loss: 0.2471 - accuracy: 0.91 - ETA: 1s - loss: 0.2450 - accuracy: 0.91 - ETA: 1s - loss: 0.2436 - accuracy: 0.91 - ETA: 0s - loss: 0.2440 - accuracy: 0.91 - ETA: 0s - loss: 0.2463 - accuracy: 0.91 - ETA: 0s - loss: 0.2462 - accuracy: 0.91 - ETA: 0s - loss: 0.2471 - accuracy: 0.91 - ETA: 0s - loss: 0.2476 - accuracy: 0.91 - ETA: 0s - loss: 0.2470 - accuracy: 0.91 - ETA: 0s - loss: 0.2487 - accuracy: 0.90 - ETA: 0s - loss: 0.2478 - accuracy: 0.90 - ETA: 0s - loss: 0.2480 - accuracy: 0.90 - ETA: 0s - loss: 0.2483 - accuracy: 0.90 - ETA: 0s - loss: 0.2486 - accuracy: 0.90 - ETA: 0s - loss: 0.2491 - accuracy: 0.90 - ETA: 0s - loss: 0.2481 - accuracy: 0.90 - ETA: 0s - loss: 0.2476 - accuracy: 0.90 - 5s 47ms/step - loss: 0.2479 - accuracy: 0.9080 - val_loss: 0.2316 - val_accuracy: 0.9015\n",
      "Epoch 6/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.90 - ETA: 2s - loss: 0.1608 - accuracy: 0.93 - ETA: 3s - loss: 0.1800 - accuracy: 0.92 - ETA: 3s - loss: 0.2062 - accuracy: 0.91 - ETA: 3s - loss: 0.2079 - accuracy: 0.92 - ETA: 4s - loss: 0.2199 - accuracy: 0.92 - ETA: 4s - loss: 0.2008 - accuracy: 0.93 - ETA: 3s - loss: 0.2249 - accuracy: 0.92 - ETA: 3s - loss: 0.2240 - accuracy: 0.93 - ETA: 3s - loss: 0.2173 - accuracy: 0.93 - ETA: 3s - loss: 0.2190 - accuracy: 0.93 - ETA: 3s - loss: 0.2235 - accuracy: 0.93 - ETA: 3s - loss: 0.2272 - accuracy: 0.92 - ETA: 3s - loss: 0.2238 - accuracy: 0.92 - ETA: 3s - loss: 0.2190 - accuracy: 0.92 - ETA: 3s - loss: 0.2191 - accuracy: 0.93 - ETA: 3s - loss: 0.2167 - accuracy: 0.93 - ETA: 3s - loss: 0.2162 - accuracy: 0.93 - ETA: 3s - loss: 0.2189 - accuracy: 0.93 - ETA: 3s - loss: 0.2167 - accuracy: 0.93 - ETA: 3s - loss: 0.2167 - accuracy: 0.92 - ETA: 3s - loss: 0.2156 - accuracy: 0.93 - ETA: 2s - loss: 0.2179 - accuracy: 0.92 - ETA: 2s - loss: 0.2175 - accuracy: 0.92 - ETA: 2s - loss: 0.2225 - accuracy: 0.92 - ETA: 2s - loss: 0.2209 - accuracy: 0.92 - ETA: 2s - loss: 0.2184 - accuracy: 0.92 - ETA: 2s - loss: 0.2201 - accuracy: 0.92 - ETA: 2s - loss: 0.2215 - accuracy: 0.92 - ETA: 2s - loss: 0.2191 - accuracy: 0.92 - ETA: 2s - loss: 0.2228 - accuracy: 0.92 - ETA: 2s - loss: 0.2273 - accuracy: 0.92 - ETA: 2s - loss: 0.2238 - accuracy: 0.92 - ETA: 2s - loss: 0.2230 - accuracy: 0.92 - ETA: 2s - loss: 0.2231 - accuracy: 0.92 - ETA: 2s - loss: 0.2251 - accuracy: 0.92 - ETA: 1s - loss: 0.2234 - accuracy: 0.92 - ETA: 1s - loss: 0.2226 - accuracy: 0.92 - ETA: 1s - loss: 0.2213 - accuracy: 0.92 - ETA: 1s - loss: 0.2185 - accuracy: 0.92 - ETA: 1s - loss: 0.2206 - accuracy: 0.92 - ETA: 1s - loss: 0.2186 - accuracy: 0.92 - ETA: 1s - loss: 0.2185 - accuracy: 0.92 - ETA: 1s - loss: 0.2159 - accuracy: 0.92 - ETA: 1s - loss: 0.2150 - accuracy: 0.92 - ETA: 1s - loss: 0.2144 - accuracy: 0.92 - ETA: 1s - loss: 0.2153 - accuracy: 0.92 - ETA: 1s - loss: 0.2165 - accuracy: 0.92 - ETA: 1s - loss: 0.2164 - accuracy: 0.92 - ETA: 1s - loss: 0.2168 - accuracy: 0.92 - ETA: 1s - loss: 0.2168 - accuracy: 0.92 - ETA: 0s - loss: 0.2164 - accuracy: 0.92 - ETA: 0s - loss: 0.2155 - accuracy: 0.92 - ETA: 0s - loss: 0.2168 - accuracy: 0.92 - ETA: 0s - loss: 0.2180 - accuracy: 0.92 - ETA: 0s - loss: 0.2174 - accuracy: 0.92 - ETA: 0s - loss: 0.2164 - accuracy: 0.92 - ETA: 0s - loss: 0.2161 - accuracy: 0.92 - ETA: 0s - loss: 0.2154 - accuracy: 0.92 - ETA: 0s - loss: 0.2142 - accuracy: 0.92 - ETA: 0s - loss: 0.2129 - accuracy: 0.92 - ETA: 0s - loss: 0.2137 - accuracy: 0.92 - ETA: 0s - loss: 0.2137 - accuracy: 0.92 - ETA: 0s - loss: 0.2129 - accuracy: 0.92 - ETA: 0s - loss: 0.2137 - accuracy: 0.92 - ETA: 0s - loss: 0.2122 - accuracy: 0.92 - ETA: 0s - loss: 0.2115 - accuracy: 0.92 - ETA: 0s - loss: 0.2105 - accuracy: 0.92 - ETA: 0s - loss: 0.2130 - accuracy: 0.92 - ETA: 0s - loss: 0.2123 - accuracy: 0.92 - ETA: 0s - loss: 0.2124 - accuracy: 0.92 - ETA: 0s - loss: 0.2113 - accuracy: 0.92 - 5s 52ms/step - loss: 0.2107 - accuracy: 0.9254 - val_loss: 0.1757 - val_accuracy: 0.9234\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.90 - ETA: 3s - loss: 0.1825 - accuracy: 0.93 - ETA: 3s - loss: 0.1990 - accuracy: 0.93 - ETA: 4s - loss: 0.1966 - accuracy: 0.92 - ETA: 4s - loss: 0.1823 - accuracy: 0.92 - ETA: 4s - loss: 0.1764 - accuracy: 0.92 - ETA: 4s - loss: 0.1702 - accuracy: 0.93 - ETA: 4s - loss: 0.1688 - accuracy: 0.93 - ETA: 4s - loss: 0.1810 - accuracy: 0.93 - ETA: 4s - loss: 0.1754 - accuracy: 0.93 - ETA: 4s - loss: 0.1681 - accuracy: 0.93 - ETA: 4s - loss: 0.1672 - accuracy: 0.94 - ETA: 4s - loss: 0.1669 - accuracy: 0.94 - ETA: 4s - loss: 0.1726 - accuracy: 0.93 - ETA: 4s - loss: 0.1675 - accuracy: 0.94 - ETA: 4s - loss: 0.1639 - accuracy: 0.94 - ETA: 4s - loss: 0.1629 - accuracy: 0.94 - ETA: 4s - loss: 0.1678 - accuracy: 0.93 - ETA: 4s - loss: 0.1660 - accuracy: 0.93 - ETA: 4s - loss: 0.1655 - accuracy: 0.93 - ETA: 4s - loss: 0.1676 - accuracy: 0.93 - ETA: 4s - loss: 0.1685 - accuracy: 0.94 - ETA: 4s - loss: 0.1678 - accuracy: 0.93 - ETA: 4s - loss: 0.1738 - accuracy: 0.93 - ETA: 3s - loss: 0.1798 - accuracy: 0.93 - ETA: 3s - loss: 0.1796 - accuracy: 0.93 - ETA: 3s - loss: 0.1809 - accuracy: 0.93 - ETA: 3s - loss: 0.1826 - accuracy: 0.93 - ETA: 3s - loss: 0.1786 - accuracy: 0.93 - ETA: 3s - loss: 0.1791 - accuracy: 0.93 - ETA: 3s - loss: 0.1820 - accuracy: 0.93 - ETA: 3s - loss: 0.1841 - accuracy: 0.93 - ETA: 3s - loss: 0.1862 - accuracy: 0.92 - ETA: 3s - loss: 0.1839 - accuracy: 0.93 - ETA: 3s - loss: 0.1848 - accuracy: 0.93 - ETA: 3s - loss: 0.1855 - accuracy: 0.92 - ETA: 3s - loss: 0.1831 - accuracy: 0.93 - ETA: 3s - loss: 0.1830 - accuracy: 0.93 - ETA: 2s - loss: 0.1852 - accuracy: 0.92 - ETA: 2s - loss: 0.1868 - accuracy: 0.92 - ETA: 2s - loss: 0.1860 - accuracy: 0.93 - ETA: 2s - loss: 0.1856 - accuracy: 0.93 - ETA: 2s - loss: 0.1897 - accuracy: 0.92 - ETA: 2s - loss: 0.1926 - accuracy: 0.92 - ETA: 2s - loss: 0.1914 - accuracy: 0.92 - ETA: 2s - loss: 0.1885 - accuracy: 0.92 - ETA: 2s - loss: 0.1872 - accuracy: 0.92 - ETA: 2s - loss: 0.1893 - accuracy: 0.92 - ETA: 2s - loss: 0.1901 - accuracy: 0.92 - ETA: 2s - loss: 0.1888 - accuracy: 0.92 - ETA: 2s - loss: 0.1882 - accuracy: 0.93 - ETA: 2s - loss: 0.1884 - accuracy: 0.93 - ETA: 1s - loss: 0.1902 - accuracy: 0.92 - ETA: 1s - loss: 0.1887 - accuracy: 0.93 - ETA: 1s - loss: 0.1895 - accuracy: 0.92 - ETA: 1s - loss: 0.1908 - accuracy: 0.92 - ETA: 1s - loss: 0.1898 - accuracy: 0.92 - ETA: 1s - loss: 0.1886 - accuracy: 0.92 - ETA: 1s - loss: 0.1880 - accuracy: 0.92 - ETA: 1s - loss: 0.1883 - accuracy: 0.92 - ETA: 1s - loss: 0.1907 - accuracy: 0.92 - ETA: 1s - loss: 0.1888 - accuracy: 0.92 - ETA: 1s - loss: 0.1909 - accuracy: 0.92 - ETA: 1s - loss: 0.1934 - accuracy: 0.92 - ETA: 0s - loss: 0.1927 - accuracy: 0.92 - ETA: 0s - loss: 0.1925 - accuracy: 0.92 - ETA: 0s - loss: 0.1928 - accuracy: 0.92 - ETA: 0s - loss: 0.1955 - accuracy: 0.92 - ETA: 0s - loss: 0.1956 - accuracy: 0.92 - ETA: 0s - loss: 0.1960 - accuracy: 0.92 - ETA: 0s - loss: 0.1960 - accuracy: 0.92 - ETA: 0s - loss: 0.1961 - accuracy: 0.92 - ETA: 0s - loss: 0.1972 - accuracy: 0.92 - ETA: 0s - loss: 0.1981 - accuracy: 0.92 - ETA: 0s - loss: 0.1994 - accuracy: 0.92 - 6s 54ms/step - loss: 0.1994 - accuracy: 0.9242 - val_loss: 0.1863 - val_accuracy: 0.9209\n",
      "Epoch 8/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.84 - ETA: 2s - loss: 0.1815 - accuracy: 0.88 - ETA: 3s - loss: 0.1493 - accuracy: 0.91 - ETA: 3s - loss: 0.1532 - accuracy: 0.92 - ETA: 3s - loss: 0.1582 - accuracy: 0.92 - ETA: 3s - loss: 0.1485 - accuracy: 0.92 - ETA: 3s - loss: 0.1592 - accuracy: 0.92 - ETA: 3s - loss: 0.1608 - accuracy: 0.92 - ETA: 3s - loss: 0.1662 - accuracy: 0.92 - ETA: 3s - loss: 0.1676 - accuracy: 0.92 - ETA: 3s - loss: 0.1629 - accuracy: 0.92 - ETA: 3s - loss: 0.1627 - accuracy: 0.92 - ETA: 3s - loss: 0.1642 - accuracy: 0.92 - ETA: 3s - loss: 0.1664 - accuracy: 0.92 - ETA: 3s - loss: 0.1662 - accuracy: 0.92 - ETA: 3s - loss: 0.1632 - accuracy: 0.93 - ETA: 3s - loss: 0.1690 - accuracy: 0.92 - ETA: 3s - loss: 0.1729 - accuracy: 0.92 - ETA: 3s - loss: 0.1792 - accuracy: 0.92 - ETA: 3s - loss: 0.1775 - accuracy: 0.92 - ETA: 3s - loss: 0.1808 - accuracy: 0.92 - ETA: 2s - loss: 0.1820 - accuracy: 0.92 - ETA: 2s - loss: 0.1855 - accuracy: 0.92 - ETA: 2s - loss: 0.1856 - accuracy: 0.92 - ETA: 2s - loss: 0.1843 - accuracy: 0.92 - ETA: 2s - loss: 0.1880 - accuracy: 0.92 - ETA: 2s - loss: 0.1881 - accuracy: 0.92 - ETA: 2s - loss: 0.1885 - accuracy: 0.92 - ETA: 2s - loss: 0.1866 - accuracy: 0.92 - ETA: 2s - loss: 0.1836 - accuracy: 0.92 - ETA: 2s - loss: 0.1810 - accuracy: 0.92 - ETA: 2s - loss: 0.1813 - accuracy: 0.92 - ETA: 2s - loss: 0.1789 - accuracy: 0.92 - ETA: 2s - loss: 0.1818 - accuracy: 0.92 - ETA: 1s - loss: 0.1795 - accuracy: 0.92 - ETA: 1s - loss: 0.1781 - accuracy: 0.92 - ETA: 1s - loss: 0.1804 - accuracy: 0.92 - ETA: 1s - loss: 0.1807 - accuracy: 0.92 - ETA: 1s - loss: 0.1821 - accuracy: 0.92 - ETA: 1s - loss: 0.1853 - accuracy: 0.92 - ETA: 1s - loss: 0.1842 - accuracy: 0.92 - ETA: 1s - loss: 0.1845 - accuracy: 0.92 - ETA: 1s - loss: 0.1846 - accuracy: 0.92 - ETA: 1s - loss: 0.1850 - accuracy: 0.92 - ETA: 1s - loss: 0.1847 - accuracy: 0.92 - ETA: 1s - loss: 0.1848 - accuracy: 0.92 - ETA: 1s - loss: 0.1847 - accuracy: 0.92 - ETA: 1s - loss: 0.1837 - accuracy: 0.92 - ETA: 0s - loss: 0.1840 - accuracy: 0.92 - ETA: 0s - loss: 0.1838 - accuracy: 0.92 - ETA: 0s - loss: 0.1829 - accuracy: 0.92 - ETA: 0s - loss: 0.1818 - accuracy: 0.92 - ETA: 0s - loss: 0.1818 - accuracy: 0.92 - ETA: 0s - loss: 0.1826 - accuracy: 0.92 - ETA: 0s - loss: 0.1841 - accuracy: 0.92 - ETA: 0s - loss: 0.1848 - accuracy: 0.92 - ETA: 0s - loss: 0.1856 - accuracy: 0.92 - ETA: 0s - loss: 0.1863 - accuracy: 0.92 - ETA: 0s - loss: 0.1860 - accuracy: 0.92 - ETA: 0s - loss: 0.1845 - accuracy: 0.92 - ETA: 0s - loss: 0.1837 - accuracy: 0.92 - 5s 47ms/step - loss: 0.1831 - accuracy: 0.9278 - val_loss: 0.1608 - val_accuracy: 0.9307\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.96 - ETA: 2s - loss: 0.1739 - accuracy: 0.94 - ETA: 3s - loss: 0.1780 - accuracy: 0.93 - ETA: 3s - loss: 0.1496 - accuracy: 0.94 - ETA: 3s - loss: 0.1421 - accuracy: 0.95 - ETA: 3s - loss: 0.1396 - accuracy: 0.95 - ETA: 3s - loss: 0.1376 - accuracy: 0.95 - ETA: 3s - loss: 0.1373 - accuracy: 0.95 - ETA: 3s - loss: 0.1395 - accuracy: 0.94 - ETA: 3s - loss: 0.1338 - accuracy: 0.95 - ETA: 3s - loss: 0.1342 - accuracy: 0.95 - ETA: 3s - loss: 0.1355 - accuracy: 0.95 - ETA: 3s - loss: 0.1339 - accuracy: 0.95 - ETA: 3s - loss: 0.1305 - accuracy: 0.95 - ETA: 3s - loss: 0.1287 - accuracy: 0.95 - ETA: 3s - loss: 0.1298 - accuracy: 0.95 - ETA: 3s - loss: 0.1279 - accuracy: 0.95 - ETA: 3s - loss: 0.1259 - accuracy: 0.95 - ETA: 3s - loss: 0.1239 - accuracy: 0.95 - ETA: 3s - loss: 0.1327 - accuracy: 0.95 - ETA: 3s - loss: 0.1447 - accuracy: 0.95 - ETA: 3s - loss: 0.1457 - accuracy: 0.95 - ETA: 2s - loss: 0.1435 - accuracy: 0.95 - ETA: 2s - loss: 0.1441 - accuracy: 0.95 - ETA: 2s - loss: 0.1489 - accuracy: 0.95 - ETA: 2s - loss: 0.1569 - accuracy: 0.94 - ETA: 2s - loss: 0.1583 - accuracy: 0.94 - ETA: 2s - loss: 0.1609 - accuracy: 0.94 - ETA: 2s - loss: 0.1628 - accuracy: 0.94 - ETA: 2s - loss: 0.1655 - accuracy: 0.93 - ETA: 2s - loss: 0.1650 - accuracy: 0.93 - ETA: 2s - loss: 0.1628 - accuracy: 0.94 - ETA: 2s - loss: 0.1674 - accuracy: 0.93 - ETA: 2s - loss: 0.1680 - accuracy: 0.93 - ETA: 2s - loss: 0.1686 - accuracy: 0.93 - ETA: 2s - loss: 0.1731 - accuracy: 0.93 - ETA: 2s - loss: 0.1725 - accuracy: 0.93 - ETA: 1s - loss: 0.1718 - accuracy: 0.93 - ETA: 1s - loss: 0.1714 - accuracy: 0.93 - ETA: 1s - loss: 0.1721 - accuracy: 0.93 - ETA: 1s - loss: 0.1719 - accuracy: 0.93 - ETA: 1s - loss: 0.1708 - accuracy: 0.93 - ETA: 1s - loss: 0.1694 - accuracy: 0.93 - ETA: 1s - loss: 0.1677 - accuracy: 0.93 - ETA: 1s - loss: 0.1689 - accuracy: 0.93 - ETA: 1s - loss: 0.1700 - accuracy: 0.93 - ETA: 1s - loss: 0.1720 - accuracy: 0.93 - ETA: 1s - loss: 0.1721 - accuracy: 0.93 - ETA: 1s - loss: 0.1737 - accuracy: 0.93 - ETA: 1s - loss: 0.1737 - accuracy: 0.93 - ETA: 1s - loss: 0.1740 - accuracy: 0.93 - ETA: 1s - loss: 0.1727 - accuracy: 0.93 - ETA: 0s - loss: 0.1717 - accuracy: 0.93 - ETA: 0s - loss: 0.1695 - accuracy: 0.93 - ETA: 0s - loss: 0.1684 - accuracy: 0.93 - ETA: 0s - loss: 0.1685 - accuracy: 0.93 - ETA: 0s - loss: 0.1682 - accuracy: 0.93 - ETA: 0s - loss: 0.1691 - accuracy: 0.93 - ETA: 0s - loss: 0.1695 - accuracy: 0.93 - ETA: 0s - loss: 0.1684 - accuracy: 0.93 - ETA: 0s - loss: 0.1686 - accuracy: 0.93 - ETA: 0s - loss: 0.1683 - accuracy: 0.93 - ETA: 0s - loss: 0.1679 - accuracy: 0.93 - ETA: 0s - loss: 0.1683 - accuracy: 0.93 - ETA: 0s - loss: 0.1680 - accuracy: 0.93 - 5s 47ms/step - loss: 0.1680 - accuracy: 0.9373 - val_loss: 0.1513 - val_accuracy: 0.9331\n",
      "Epoch 10/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.90 - ETA: 2s - loss: 0.1673 - accuracy: 0.92 - ETA: 3s - loss: 0.2044 - accuracy: 0.91 - ETA: 3s - loss: 0.1677 - accuracy: 0.93 - ETA: 3s - loss: 0.1604 - accuracy: 0.93 - ETA: 3s - loss: 0.1761 - accuracy: 0.92 - ETA: 3s - loss: 0.1671 - accuracy: 0.93 - ETA: 3s - loss: 0.1636 - accuracy: 0.93 - ETA: 3s - loss: 0.1772 - accuracy: 0.92 - ETA: 3s - loss: 0.1727 - accuracy: 0.92 - ETA: 3s - loss: 0.1739 - accuracy: 0.92 - ETA: 3s - loss: 0.1765 - accuracy: 0.93 - ETA: 3s - loss: 0.1702 - accuracy: 0.93 - ETA: 3s - loss: 0.1750 - accuracy: 0.93 - ETA: 3s - loss: 0.1694 - accuracy: 0.93 - ETA: 3s - loss: 0.1681 - accuracy: 0.93 - ETA: 3s - loss: 0.1660 - accuracy: 0.93 - ETA: 3s - loss: 0.1671 - accuracy: 0.93 - ETA: 3s - loss: 0.1633 - accuracy: 0.93 - ETA: 3s - loss: 0.1666 - accuracy: 0.93 - ETA: 2s - loss: 0.1643 - accuracy: 0.93 - ETA: 2s - loss: 0.1647 - accuracy: 0.93 - ETA: 2s - loss: 0.1677 - accuracy: 0.93 - ETA: 2s - loss: 0.1696 - accuracy: 0.93 - ETA: 2s - loss: 0.1672 - accuracy: 0.93 - ETA: 2s - loss: 0.1646 - accuracy: 0.93 - ETA: 2s - loss: 0.1646 - accuracy: 0.94 - ETA: 2s - loss: 0.1646 - accuracy: 0.93 - ETA: 2s - loss: 0.1634 - accuracy: 0.93 - ETA: 2s - loss: 0.1623 - accuracy: 0.93 - ETA: 2s - loss: 0.1598 - accuracy: 0.93 - ETA: 2s - loss: 0.1614 - accuracy: 0.93 - ETA: 2s - loss: 0.1633 - accuracy: 0.93 - ETA: 2s - loss: 0.1628 - accuracy: 0.93 - ETA: 1s - loss: 0.1616 - accuracy: 0.94 - ETA: 1s - loss: 0.1584 - accuracy: 0.94 - ETA: 1s - loss: 0.1616 - accuracy: 0.94 - ETA: 1s - loss: 0.1616 - accuracy: 0.94 - ETA: 1s - loss: 0.1602 - accuracy: 0.94 - ETA: 1s - loss: 0.1586 - accuracy: 0.94 - ETA: 1s - loss: 0.1589 - accuracy: 0.94 - ETA: 1s - loss: 0.1582 - accuracy: 0.94 - ETA: 1s - loss: 0.1591 - accuracy: 0.94 - ETA: 1s - loss: 0.1613 - accuracy: 0.94 - ETA: 1s - loss: 0.1607 - accuracy: 0.94 - ETA: 1s - loss: 0.1591 - accuracy: 0.94 - ETA: 1s - loss: 0.1565 - accuracy: 0.94 - ETA: 0s - loss: 0.1574 - accuracy: 0.94 - ETA: 0s - loss: 0.1553 - accuracy: 0.94 - ETA: 0s - loss: 0.1553 - accuracy: 0.94 - ETA: 0s - loss: 0.1543 - accuracy: 0.94 - ETA: 0s - loss: 0.1564 - accuracy: 0.94 - ETA: 0s - loss: 0.1588 - accuracy: 0.94 - ETA: 0s - loss: 0.1585 - accuracy: 0.94 - ETA: 0s - loss: 0.1593 - accuracy: 0.94 - ETA: 0s - loss: 0.1608 - accuracy: 0.93 - ETA: 0s - loss: 0.1605 - accuracy: 0.94 - ETA: 0s - loss: 0.1604 - accuracy: 0.94 - ETA: 0s - loss: 0.1598 - accuracy: 0.94 - ETA: 0s - loss: 0.1594 - accuracy: 0.94 - 5s 46ms/step - loss: 0.1594 - accuracy: 0.9409 - val_loss: 0.1647 - val_accuracy: 0.9258\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.96 - ETA: 2s - loss: 0.0849 - accuracy: 0.97 - ETA: 3s - loss: 0.0832 - accuracy: 0.97 - ETA: 3s - loss: 0.0915 - accuracy: 0.97 - ETA: 3s - loss: 0.0851 - accuracy: 0.97 - ETA: 3s - loss: 0.1009 - accuracy: 0.97 - ETA: 3s - loss: 0.1238 - accuracy: 0.95 - ETA: 3s - loss: 0.1271 - accuracy: 0.95 - ETA: 3s - loss: 0.1256 - accuracy: 0.95 - ETA: 3s - loss: 0.1233 - accuracy: 0.95 - ETA: 3s - loss: 0.1275 - accuracy: 0.95 - ETA: 3s - loss: 0.1235 - accuracy: 0.95 - ETA: 3s - loss: 0.1213 - accuracy: 0.95 - ETA: 3s - loss: 0.1195 - accuracy: 0.95 - ETA: 3s - loss: 0.1234 - accuracy: 0.95 - ETA: 3s - loss: 0.1212 - accuracy: 0.95 - ETA: 3s - loss: 0.1201 - accuracy: 0.95 - ETA: 3s - loss: 0.1216 - accuracy: 0.95 - ETA: 3s - loss: 0.1215 - accuracy: 0.95 - ETA: 3s - loss: 0.1254 - accuracy: 0.95 - ETA: 3s - loss: 0.1241 - accuracy: 0.95 - ETA: 3s - loss: 0.1259 - accuracy: 0.95 - ETA: 3s - loss: 0.1291 - accuracy: 0.95 - ETA: 2s - loss: 0.1286 - accuracy: 0.95 - ETA: 2s - loss: 0.1354 - accuracy: 0.95 - ETA: 2s - loss: 0.1370 - accuracy: 0.95 - ETA: 2s - loss: 0.1370 - accuracy: 0.95 - ETA: 2s - loss: 0.1352 - accuracy: 0.95 - ETA: 2s - loss: 0.1355 - accuracy: 0.95 - ETA: 2s - loss: 0.1381 - accuracy: 0.94 - ETA: 2s - loss: 0.1377 - accuracy: 0.94 - ETA: 2s - loss: 0.1388 - accuracy: 0.94 - ETA: 2s - loss: 0.1406 - accuracy: 0.94 - ETA: 2s - loss: 0.1415 - accuracy: 0.94 - ETA: 2s - loss: 0.1431 - accuracy: 0.94 - ETA: 2s - loss: 0.1447 - accuracy: 0.94 - ETA: 2s - loss: 0.1438 - accuracy: 0.94 - ETA: 1s - loss: 0.1418 - accuracy: 0.94 - ETA: 1s - loss: 0.1409 - accuracy: 0.94 - ETA: 1s - loss: 0.1402 - accuracy: 0.94 - ETA: 1s - loss: 0.1406 - accuracy: 0.94 - ETA: 1s - loss: 0.1411 - accuracy: 0.94 - ETA: 1s - loss: 0.1432 - accuracy: 0.94 - ETA: 1s - loss: 0.1458 - accuracy: 0.94 - ETA: 1s - loss: 0.1446 - accuracy: 0.94 - ETA: 1s - loss: 0.1452 - accuracy: 0.94 - ETA: 1s - loss: 0.1474 - accuracy: 0.94 - ETA: 1s - loss: 0.1463 - accuracy: 0.94 - ETA: 1s - loss: 0.1449 - accuracy: 0.94 - ETA: 1s - loss: 0.1449 - accuracy: 0.94 - ETA: 0s - loss: 0.1450 - accuracy: 0.94 - ETA: 0s - loss: 0.1459 - accuracy: 0.94 - ETA: 0s - loss: 0.1471 - accuracy: 0.94 - ETA: 0s - loss: 0.1480 - accuracy: 0.94 - ETA: 0s - loss: 0.1496 - accuracy: 0.94 - ETA: 0s - loss: 0.1486 - accuracy: 0.94 - ETA: 0s - loss: 0.1495 - accuracy: 0.94 - ETA: 0s - loss: 0.1495 - accuracy: 0.94 - ETA: 0s - loss: 0.1497 - accuracy: 0.94 - ETA: 0s - loss: 0.1494 - accuracy: 0.94 - ETA: 0s - loss: 0.1477 - accuracy: 0.94 - ETA: 0s - loss: 0.1478 - accuracy: 0.94 - ETA: 0s - loss: 0.1477 - accuracy: 0.94 - ETA: 0s - loss: 0.1469 - accuracy: 0.94 - 5s 48ms/step - loss: 0.1469 - accuracy: 0.9440 - val_loss: 0.1360 - val_accuracy: 0.9392\n",
      "Epoch 12/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.93 - ETA: 2s - loss: 0.0903 - accuracy: 0.94 - ETA: 3s - loss: 0.1074 - accuracy: 0.95 - ETA: 3s - loss: 0.1403 - accuracy: 0.94 - ETA: 3s - loss: 0.1441 - accuracy: 0.93 - ETA: 3s - loss: 0.1336 - accuracy: 0.94 - ETA: 3s - loss: 0.1257 - accuracy: 0.95 - ETA: 3s - loss: 0.1367 - accuracy: 0.95 - ETA: 3s - loss: 0.1406 - accuracy: 0.94 - ETA: 3s - loss: 0.1392 - accuracy: 0.94 - ETA: 3s - loss: 0.1412 - accuracy: 0.94 - ETA: 3s - loss: 0.1443 - accuracy: 0.94 - ETA: 3s - loss: 0.1472 - accuracy: 0.94 - ETA: 3s - loss: 0.1500 - accuracy: 0.94 - ETA: 3s - loss: 0.1470 - accuracy: 0.94 - ETA: 3s - loss: 0.1474 - accuracy: 0.94 - ETA: 3s - loss: 0.1446 - accuracy: 0.94 - ETA: 3s - loss: 0.1399 - accuracy: 0.94 - ETA: 3s - loss: 0.1413 - accuracy: 0.94 - ETA: 3s - loss: 0.1462 - accuracy: 0.93 - ETA: 2s - loss: 0.1446 - accuracy: 0.93 - ETA: 2s - loss: 0.1449 - accuracy: 0.93 - ETA: 2s - loss: 0.1420 - accuracy: 0.93 - ETA: 2s - loss: 0.1413 - accuracy: 0.94 - ETA: 2s - loss: 0.1411 - accuracy: 0.94 - ETA: 2s - loss: 0.1423 - accuracy: 0.94 - ETA: 2s - loss: 0.1400 - accuracy: 0.94 - ETA: 2s - loss: 0.1406 - accuracy: 0.94 - ETA: 2s - loss: 0.1398 - accuracy: 0.94 - ETA: 2s - loss: 0.1392 - accuracy: 0.94 - ETA: 2s - loss: 0.1406 - accuracy: 0.94 - ETA: 2s - loss: 0.1384 - accuracy: 0.94 - ETA: 2s - loss: 0.1377 - accuracy: 0.94 - ETA: 2s - loss: 0.1366 - accuracy: 0.94 - ETA: 1s - loss: 0.1382 - accuracy: 0.94 - ETA: 1s - loss: 0.1369 - accuracy: 0.94 - ETA: 1s - loss: 0.1373 - accuracy: 0.94 - ETA: 1s - loss: 0.1371 - accuracy: 0.94 - ETA: 1s - loss: 0.1382 - accuracy: 0.94 - ETA: 1s - loss: 0.1389 - accuracy: 0.94 - ETA: 1s - loss: 0.1386 - accuracy: 0.94 - ETA: 1s - loss: 0.1392 - accuracy: 0.94 - ETA: 1s - loss: 0.1382 - accuracy: 0.94 - ETA: 1s - loss: 0.1376 - accuracy: 0.94 - ETA: 1s - loss: 0.1372 - accuracy: 0.94 - ETA: 1s - loss: 0.1365 - accuracy: 0.94 - ETA: 1s - loss: 0.1360 - accuracy: 0.94 - ETA: 0s - loss: 0.1377 - accuracy: 0.94 - ETA: 0s - loss: 0.1380 - accuracy: 0.94 - ETA: 0s - loss: 0.1365 - accuracy: 0.94 - ETA: 0s - loss: 0.1363 - accuracy: 0.94 - ETA: 0s - loss: 0.1359 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1342 - accuracy: 0.94 - ETA: 0s - loss: 0.1340 - accuracy: 0.94 - ETA: 0s - loss: 0.1331 - accuracy: 0.94 - ETA: 0s - loss: 0.1325 - accuracy: 0.94 - ETA: 0s - loss: 0.1321 - accuracy: 0.94 - ETA: 0s - loss: 0.1348 - accuracy: 0.94 - ETA: 0s - loss: 0.1353 - accuracy: 0.94 - 5s 46ms/step - loss: 0.1353 - accuracy: 0.9479 - val_loss: 0.1446 - val_accuracy: 0.9404\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.93 - ETA: 2s - loss: 0.1364 - accuracy: 0.95 - ETA: 3s - loss: 0.1551 - accuracy: 0.95 - ETA: 3s - loss: 0.1408 - accuracy: 0.95 - ETA: 3s - loss: 0.1328 - accuracy: 0.95 - ETA: 3s - loss: 0.1313 - accuracy: 0.95 - ETA: 3s - loss: 0.1271 - accuracy: 0.95 - ETA: 3s - loss: 0.1237 - accuracy: 0.96 - ETA: 3s - loss: 0.1212 - accuracy: 0.95 - ETA: 3s - loss: 0.1373 - accuracy: 0.95 - ETA: 3s - loss: 0.1374 - accuracy: 0.94 - ETA: 3s - loss: 0.1324 - accuracy: 0.95 - ETA: 3s - loss: 0.1325 - accuracy: 0.95 - ETA: 3s - loss: 0.1294 - accuracy: 0.95 - ETA: 3s - loss: 0.1296 - accuracy: 0.95 - ETA: 3s - loss: 0.1264 - accuracy: 0.95 - ETA: 3s - loss: 0.1360 - accuracy: 0.95 - ETA: 3s - loss: 0.1334 - accuracy: 0.95 - ETA: 3s - loss: 0.1317 - accuracy: 0.95 - ETA: 3s - loss: 0.1282 - accuracy: 0.95 - ETA: 3s - loss: 0.1272 - accuracy: 0.95 - ETA: 3s - loss: 0.1260 - accuracy: 0.95 - ETA: 3s - loss: 0.1259 - accuracy: 0.95 - ETA: 2s - loss: 0.1270 - accuracy: 0.95 - ETA: 2s - loss: 0.1253 - accuracy: 0.95 - ETA: 2s - loss: 0.1230 - accuracy: 0.95 - ETA: 2s - loss: 0.1215 - accuracy: 0.95 - ETA: 2s - loss: 0.1211 - accuracy: 0.95 - ETA: 2s - loss: 0.1214 - accuracy: 0.95 - ETA: 2s - loss: 0.1222 - accuracy: 0.95 - ETA: 2s - loss: 0.1242 - accuracy: 0.95 - ETA: 2s - loss: 0.1239 - accuracy: 0.95 - ETA: 2s - loss: 0.1218 - accuracy: 0.95 - ETA: 2s - loss: 0.1198 - accuracy: 0.95 - ETA: 2s - loss: 0.1215 - accuracy: 0.95 - ETA: 2s - loss: 0.1220 - accuracy: 0.95 - ETA: 2s - loss: 0.1231 - accuracy: 0.95 - ETA: 1s - loss: 0.1212 - accuracy: 0.95 - ETA: 1s - loss: 0.1220 - accuracy: 0.95 - ETA: 1s - loss: 0.1208 - accuracy: 0.95 - ETA: 1s - loss: 0.1208 - accuracy: 0.95 - ETA: 1s - loss: 0.1224 - accuracy: 0.95 - ETA: 1s - loss: 0.1219 - accuracy: 0.95 - ETA: 1s - loss: 0.1213 - accuracy: 0.95 - ETA: 1s - loss: 0.1285 - accuracy: 0.95 - ETA: 1s - loss: 0.1268 - accuracy: 0.95 - ETA: 1s - loss: 0.1271 - accuracy: 0.95 - ETA: 1s - loss: 0.1259 - accuracy: 0.95 - ETA: 1s - loss: 0.1261 - accuracy: 0.95 - ETA: 1s - loss: 0.1248 - accuracy: 0.95 - ETA: 0s - loss: 0.1249 - accuracy: 0.95 - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - ETA: 0s - loss: 0.1273 - accuracy: 0.95 - ETA: 0s - loss: 0.1283 - accuracy: 0.95 - ETA: 0s - loss: 0.1274 - accuracy: 0.95 - ETA: 0s - loss: 0.1275 - accuracy: 0.95 - ETA: 0s - loss: 0.1306 - accuracy: 0.95 - ETA: 0s - loss: 0.1311 - accuracy: 0.95 - ETA: 0s - loss: 0.1324 - accuracy: 0.95 - ETA: 0s - loss: 0.1325 - accuracy: 0.95 - ETA: 0s - loss: 0.1342 - accuracy: 0.95 - ETA: 0s - loss: 0.1347 - accuracy: 0.94 - ETA: 0s - loss: 0.1344 - accuracy: 0.94 - ETA: 0s - loss: 0.1329 - accuracy: 0.95 - 5s 47ms/step - loss: 0.1332 - accuracy: 0.9504 - val_loss: 0.1395 - val_accuracy: 0.9440\n",
      "Epoch 14/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.96 - ETA: 2s - loss: 0.0820 - accuracy: 0.97 - ETA: 3s - loss: 0.1069 - accuracy: 0.96 - ETA: 3s - loss: 0.0981 - accuracy: 0.96 - ETA: 3s - loss: 0.1096 - accuracy: 0.95 - ETA: 3s - loss: 0.1072 - accuracy: 0.96 - ETA: 3s - loss: 0.1020 - accuracy: 0.96 - ETA: 3s - loss: 0.0973 - accuracy: 0.96 - ETA: 3s - loss: 0.1074 - accuracy: 0.96 - ETA: 3s - loss: 0.1048 - accuracy: 0.96 - ETA: 3s - loss: 0.1067 - accuracy: 0.96 - ETA: 3s - loss: 0.1059 - accuracy: 0.96 - ETA: 3s - loss: 0.1119 - accuracy: 0.96 - ETA: 3s - loss: 0.1088 - accuracy: 0.96 - ETA: 3s - loss: 0.1049 - accuracy: 0.96 - ETA: 3s - loss: 0.1072 - accuracy: 0.96 - ETA: 3s - loss: 0.1058 - accuracy: 0.96 - ETA: 3s - loss: 0.1086 - accuracy: 0.96 - ETA: 3s - loss: 0.1083 - accuracy: 0.96 - ETA: 2s - loss: 0.1082 - accuracy: 0.96 - ETA: 2s - loss: 0.1078 - accuracy: 0.96 - ETA: 2s - loss: 0.1057 - accuracy: 0.96 - ETA: 2s - loss: 0.1055 - accuracy: 0.96 - ETA: 2s - loss: 0.1090 - accuracy: 0.96 - ETA: 2s - loss: 0.1100 - accuracy: 0.96 - ETA: 2s - loss: 0.1106 - accuracy: 0.96 - ETA: 2s - loss: 0.1097 - accuracy: 0.96 - ETA: 2s - loss: 0.1091 - accuracy: 0.96 - ETA: 2s - loss: 0.1083 - accuracy: 0.96 - ETA: 2s - loss: 0.1113 - accuracy: 0.96 - ETA: 2s - loss: 0.1104 - accuracy: 0.96 - ETA: 2s - loss: 0.1131 - accuracy: 0.96 - ETA: 1s - loss: 0.1127 - accuracy: 0.96 - ETA: 1s - loss: 0.1106 - accuracy: 0.96 - ETA: 1s - loss: 0.1110 - accuracy: 0.96 - ETA: 1s - loss: 0.1105 - accuracy: 0.96 - ETA: 1s - loss: 0.1100 - accuracy: 0.96 - ETA: 1s - loss: 0.1151 - accuracy: 0.96 - ETA: 1s - loss: 0.1168 - accuracy: 0.96 - ETA: 1s - loss: 0.1206 - accuracy: 0.96 - ETA: 1s - loss: 0.1210 - accuracy: 0.95 - ETA: 1s - loss: 0.1217 - accuracy: 0.95 - ETA: 1s - loss: 0.1215 - accuracy: 0.95 - ETA: 1s - loss: 0.1215 - accuracy: 0.95 - ETA: 1s - loss: 0.1231 - accuracy: 0.95 - ETA: 0s - loss: 0.1230 - accuracy: 0.95 - ETA: 0s - loss: 0.1227 - accuracy: 0.95 - ETA: 0s - loss: 0.1218 - accuracy: 0.95 - ETA: 0s - loss: 0.1219 - accuracy: 0.95 - ETA: 0s - loss: 0.1221 - accuracy: 0.95 - ETA: 0s - loss: 0.1215 - accuracy: 0.95 - ETA: 0s - loss: 0.1206 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1191 - accuracy: 0.95 - ETA: 0s - loss: 0.1186 - accuracy: 0.95 - ETA: 0s - loss: 0.1195 - accuracy: 0.95 - ETA: 0s - loss: 0.1188 - accuracy: 0.95 - 5s 46ms/step - loss: 0.1185 - accuracy: 0.9598 - val_loss: 0.1278 - val_accuracy: 0.9489\n",
      "Epoch 15/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 1.00 - ETA: 2s - loss: 0.0852 - accuracy: 0.97 - ETA: 3s - loss: 0.0926 - accuracy: 0.97 - ETA: 3s - loss: 0.0880 - accuracy: 0.97 - ETA: 3s - loss: 0.0796 - accuracy: 0.97 - ETA: 3s - loss: 0.0817 - accuracy: 0.97 - ETA: 3s - loss: 0.1024 - accuracy: 0.96 - ETA: 3s - loss: 0.1125 - accuracy: 0.96 - ETA: 3s - loss: 0.1148 - accuracy: 0.96 - ETA: 3s - loss: 0.1181 - accuracy: 0.95 - ETA: 3s - loss: 0.1186 - accuracy: 0.95 - ETA: 3s - loss: 0.1247 - accuracy: 0.95 - ETA: 3s - loss: 0.1242 - accuracy: 0.95 - ETA: 3s - loss: 0.1201 - accuracy: 0.95 - ETA: 3s - loss: 0.1205 - accuracy: 0.95 - ETA: 3s - loss: 0.1169 - accuracy: 0.95 - ETA: 3s - loss: 0.1198 - accuracy: 0.95 - ETA: 3s - loss: 0.1198 - accuracy: 0.95 - ETA: 3s - loss: 0.1210 - accuracy: 0.95 - ETA: 3s - loss: 0.1189 - accuracy: 0.95 - ETA: 3s - loss: 0.1175 - accuracy: 0.95 - ETA: 3s - loss: 0.1159 - accuracy: 0.95 - ETA: 3s - loss: 0.1156 - accuracy: 0.95 - ETA: 2s - loss: 0.1149 - accuracy: 0.95 - ETA: 2s - loss: 0.1148 - accuracy: 0.96 - ETA: 2s - loss: 0.1139 - accuracy: 0.96 - ETA: 2s - loss: 0.1137 - accuracy: 0.96 - ETA: 2s - loss: 0.1145 - accuracy: 0.96 - ETA: 2s - loss: 0.1139 - accuracy: 0.96 - ETA: 2s - loss: 0.1143 - accuracy: 0.96 - ETA: 2s - loss: 0.1163 - accuracy: 0.96 - ETA: 2s - loss: 0.1146 - accuracy: 0.96 - ETA: 2s - loss: 0.1168 - accuracy: 0.95 - ETA: 2s - loss: 0.1188 - accuracy: 0.95 - ETA: 2s - loss: 0.1198 - accuracy: 0.95 - ETA: 2s - loss: 0.1206 - accuracy: 0.95 - ETA: 2s - loss: 0.1211 - accuracy: 0.95 - ETA: 2s - loss: 0.1203 - accuracy: 0.95 - ETA: 1s - loss: 0.1187 - accuracy: 0.95 - ETA: 1s - loss: 0.1178 - accuracy: 0.95 - ETA: 1s - loss: 0.1176 - accuracy: 0.95 - ETA: 1s - loss: 0.1175 - accuracy: 0.95 - ETA: 1s - loss: 0.1172 - accuracy: 0.95 - ETA: 1s - loss: 0.1150 - accuracy: 0.95 - ETA: 1s - loss: 0.1142 - accuracy: 0.95 - ETA: 1s - loss: 0.1141 - accuracy: 0.95 - ETA: 1s - loss: 0.1179 - accuracy: 0.95 - ETA: 1s - loss: 0.1175 - accuracy: 0.95 - ETA: 1s - loss: 0.1181 - accuracy: 0.95 - ETA: 1s - loss: 0.1160 - accuracy: 0.95 - ETA: 1s - loss: 0.1151 - accuracy: 0.95 - ETA: 0s - loss: 0.1129 - accuracy: 0.95 - ETA: 0s - loss: 0.1127 - accuracy: 0.95 - ETA: 0s - loss: 0.1171 - accuracy: 0.95 - ETA: 0s - loss: 0.1160 - accuracy: 0.95 - ETA: 0s - loss: 0.1142 - accuracy: 0.95 - ETA: 0s - loss: 0.1132 - accuracy: 0.96 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1144 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1138 - accuracy: 0.95 - ETA: 0s - loss: 0.1133 - accuracy: 0.95 - 5s 49ms/step - loss: 0.1128 - accuracy: 0.9598 - val_loss: 0.1203 - val_accuracy: 0.9526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 1.00 - ETA: 2s - loss: 0.1028 - accuracy: 0.97 - ETA: 3s - loss: 0.1237 - accuracy: 0.96 - ETA: 3s - loss: 0.1175 - accuracy: 0.96 - ETA: 3s - loss: 0.1021 - accuracy: 0.96 - ETA: 3s - loss: 0.1189 - accuracy: 0.96 - ETA: 4s - loss: 0.1224 - accuracy: 0.95 - ETA: 3s - loss: 0.1244 - accuracy: 0.96 - ETA: 3s - loss: 0.1126 - accuracy: 0.96 - ETA: 3s - loss: 0.1064 - accuracy: 0.96 - ETA: 3s - loss: 0.1120 - accuracy: 0.96 - ETA: 3s - loss: 0.1103 - accuracy: 0.96 - ETA: 3s - loss: 0.1077 - accuracy: 0.96 - ETA: 3s - loss: 0.1170 - accuracy: 0.96 - ETA: 3s - loss: 0.1145 - accuracy: 0.96 - ETA: 3s - loss: 0.1136 - accuracy: 0.96 - ETA: 3s - loss: 0.1143 - accuracy: 0.96 - ETA: 3s - loss: 0.1183 - accuracy: 0.95 - ETA: 3s - loss: 0.1158 - accuracy: 0.96 - ETA: 3s - loss: 0.1134 - accuracy: 0.96 - ETA: 3s - loss: 0.1167 - accuracy: 0.96 - ETA: 3s - loss: 0.1197 - accuracy: 0.96 - ETA: 3s - loss: 0.1193 - accuracy: 0.96 - ETA: 3s - loss: 0.1242 - accuracy: 0.95 - ETA: 2s - loss: 0.1265 - accuracy: 0.95 - ETA: 2s - loss: 0.1243 - accuracy: 0.95 - ETA: 2s - loss: 0.1287 - accuracy: 0.95 - ETA: 2s - loss: 0.1275 - accuracy: 0.96 - ETA: 2s - loss: 0.1272 - accuracy: 0.95 - ETA: 2s - loss: 0.1249 - accuracy: 0.95 - ETA: 2s - loss: 0.1246 - accuracy: 0.96 - ETA: 2s - loss: 0.1239 - accuracy: 0.95 - ETA: 2s - loss: 0.1231 - accuracy: 0.95 - ETA: 2s - loss: 0.1225 - accuracy: 0.95 - ETA: 2s - loss: 0.1204 - accuracy: 0.96 - ETA: 2s - loss: 0.1207 - accuracy: 0.96 - ETA: 2s - loss: 0.1220 - accuracy: 0.95 - ETA: 2s - loss: 0.1210 - accuracy: 0.95 - ETA: 1s - loss: 0.1202 - accuracy: 0.95 - ETA: 1s - loss: 0.1186 - accuracy: 0.96 - ETA: 1s - loss: 0.1180 - accuracy: 0.96 - ETA: 1s - loss: 0.1171 - accuracy: 0.96 - ETA: 1s - loss: 0.1160 - accuracy: 0.96 - ETA: 1s - loss: 0.1146 - accuracy: 0.96 - ETA: 1s - loss: 0.1129 - accuracy: 0.96 - ETA: 1s - loss: 0.1137 - accuracy: 0.96 - ETA: 1s - loss: 0.1118 - accuracy: 0.96 - ETA: 1s - loss: 0.1112 - accuracy: 0.96 - ETA: 1s - loss: 0.1100 - accuracy: 0.96 - ETA: 1s - loss: 0.1095 - accuracy: 0.96 - ETA: 1s - loss: 0.1098 - accuracy: 0.96 - ETA: 1s - loss: 0.1100 - accuracy: 0.96 - ETA: 1s - loss: 0.1097 - accuracy: 0.96 - ETA: 0s - loss: 0.1101 - accuracy: 0.96 - ETA: 0s - loss: 0.1110 - accuracy: 0.96 - ETA: 0s - loss: 0.1117 - accuracy: 0.96 - ETA: 0s - loss: 0.1110 - accuracy: 0.96 - ETA: 0s - loss: 0.1111 - accuracy: 0.96 - ETA: 0s - loss: 0.1115 - accuracy: 0.96 - ETA: 0s - loss: 0.1118 - accuracy: 0.96 - ETA: 0s - loss: 0.1109 - accuracy: 0.96 - ETA: 0s - loss: 0.1101 - accuracy: 0.96 - ETA: 0s - loss: 0.1096 - accuracy: 0.96 - ETA: 0s - loss: 0.1082 - accuracy: 0.96 - ETA: 0s - loss: 0.1090 - accuracy: 0.96 - ETA: 0s - loss: 0.1103 - accuracy: 0.96 - ETA: 0s - loss: 0.1104 - accuracy: 0.96 - 5s 48ms/step - loss: 0.1104 - accuracy: 0.9613 - val_loss: 0.1305 - val_accuracy: 0.9453\n",
      "Epoch 17/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.93 - ETA: 2s - loss: 0.1087 - accuracy: 0.95 - ETA: 3s - loss: 0.1007 - accuracy: 0.96 - ETA: 3s - loss: 0.0921 - accuracy: 0.96 - ETA: 3s - loss: 0.0981 - accuracy: 0.96 - ETA: 3s - loss: 0.1034 - accuracy: 0.96 - ETA: 4s - loss: 0.0981 - accuracy: 0.96 - ETA: 4s - loss: 0.1043 - accuracy: 0.96 - ETA: 3s - loss: 0.1021 - accuracy: 0.96 - ETA: 3s - loss: 0.1015 - accuracy: 0.96 - ETA: 3s - loss: 0.1041 - accuracy: 0.95 - ETA: 3s - loss: 0.0997 - accuracy: 0.96 - ETA: 3s - loss: 0.1011 - accuracy: 0.96 - ETA: 3s - loss: 0.0991 - accuracy: 0.96 - ETA: 3s - loss: 0.0965 - accuracy: 0.96 - ETA: 3s - loss: 0.0945 - accuracy: 0.96 - ETA: 3s - loss: 0.0964 - accuracy: 0.96 - ETA: 3s - loss: 0.0968 - accuracy: 0.96 - ETA: 3s - loss: 0.0985 - accuracy: 0.96 - ETA: 3s - loss: 0.0969 - accuracy: 0.96 - ETA: 3s - loss: 0.1026 - accuracy: 0.96 - ETA: 3s - loss: 0.1014 - accuracy: 0.96 - ETA: 2s - loss: 0.1007 - accuracy: 0.96 - ETA: 2s - loss: 0.1015 - accuracy: 0.96 - ETA: 2s - loss: 0.1000 - accuracy: 0.96 - ETA: 2s - loss: 0.0993 - accuracy: 0.96 - ETA: 2s - loss: 0.0996 - accuracy: 0.96 - ETA: 2s - loss: 0.0992 - accuracy: 0.96 - ETA: 2s - loss: 0.0989 - accuracy: 0.96 - ETA: 2s - loss: 0.0973 - accuracy: 0.96 - ETA: 2s - loss: 0.0957 - accuracy: 0.96 - ETA: 2s - loss: 0.0955 - accuracy: 0.96 - ETA: 2s - loss: 0.0953 - accuracy: 0.96 - ETA: 2s - loss: 0.0964 - accuracy: 0.96 - ETA: 2s - loss: 0.0956 - accuracy: 0.96 - ETA: 1s - loss: 0.0945 - accuracy: 0.96 - ETA: 1s - loss: 0.0973 - accuracy: 0.96 - ETA: 1s - loss: 0.0982 - accuracy: 0.96 - ETA: 1s - loss: 0.0981 - accuracy: 0.96 - ETA: 1s - loss: 0.0986 - accuracy: 0.96 - ETA: 1s - loss: 0.0977 - accuracy: 0.96 - ETA: 1s - loss: 0.0992 - accuracy: 0.96 - ETA: 1s - loss: 0.1000 - accuracy: 0.96 - ETA: 1s - loss: 0.0987 - accuracy: 0.96 - ETA: 1s - loss: 0.0982 - accuracy: 0.96 - ETA: 1s - loss: 0.0993 - accuracy: 0.96 - ETA: 1s - loss: 0.1017 - accuracy: 0.96 - ETA: 1s - loss: 0.1033 - accuracy: 0.96 - ETA: 0s - loss: 0.1024 - accuracy: 0.96 - ETA: 0s - loss: 0.1018 - accuracy: 0.96 - ETA: 0s - loss: 0.1029 - accuracy: 0.96 - ETA: 0s - loss: 0.1037 - accuracy: 0.96 - ETA: 0s - loss: 0.1039 - accuracy: 0.96 - ETA: 0s - loss: 0.1036 - accuracy: 0.96 - ETA: 0s - loss: 0.1026 - accuracy: 0.96 - ETA: 0s - loss: 0.1026 - accuracy: 0.96 - ETA: 0s - loss: 0.1020 - accuracy: 0.96 - ETA: 0s - loss: 0.1017 - accuracy: 0.96 - ETA: 0s - loss: 0.1016 - accuracy: 0.96 - ETA: 0s - loss: 0.1023 - accuracy: 0.96 - ETA: 0s - loss: 0.1034 - accuracy: 0.96 - ETA: 0s - loss: 0.1042 - accuracy: 0.96 - ETA: 0s - loss: 0.1044 - accuracy: 0.96 - 5s 47ms/step - loss: 0.1039 - accuracy: 0.9619 - val_loss: 0.1274 - val_accuracy: 0.9453\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.96 - ETA: 2s - loss: 0.0446 - accuracy: 0.98 - ETA: 3s - loss: 0.1288 - accuracy: 0.93 - ETA: 3s - loss: 0.1262 - accuracy: 0.94 - ETA: 3s - loss: 0.1042 - accuracy: 0.95 - ETA: 3s - loss: 0.1021 - accuracy: 0.95 - ETA: 3s - loss: 0.1022 - accuracy: 0.95 - ETA: 3s - loss: 0.1039 - accuracy: 0.95 - ETA: 3s - loss: 0.1032 - accuracy: 0.95 - ETA: 4s - loss: 0.1048 - accuracy: 0.95 - ETA: 3s - loss: 0.1031 - accuracy: 0.95 - ETA: 3s - loss: 0.1017 - accuracy: 0.96 - ETA: 3s - loss: 0.0996 - accuracy: 0.96 - ETA: 3s - loss: 0.0979 - accuracy: 0.96 - ETA: 3s - loss: 0.0980 - accuracy: 0.96 - ETA: 3s - loss: 0.1026 - accuracy: 0.96 - ETA: 3s - loss: 0.1047 - accuracy: 0.95 - ETA: 3s - loss: 0.1022 - accuracy: 0.95 - ETA: 3s - loss: 0.1028 - accuracy: 0.95 - ETA: 3s - loss: 0.1046 - accuracy: 0.95 - ETA: 3s - loss: 0.1044 - accuracy: 0.95 - ETA: 2s - loss: 0.1012 - accuracy: 0.95 - ETA: 2s - loss: 0.0980 - accuracy: 0.96 - ETA: 2s - loss: 0.0949 - accuracy: 0.96 - ETA: 2s - loss: 0.0933 - accuracy: 0.96 - ETA: 2s - loss: 0.0954 - accuracy: 0.96 - ETA: 2s - loss: 0.0963 - accuracy: 0.96 - ETA: 2s - loss: 0.0950 - accuracy: 0.96 - ETA: 2s - loss: 0.0934 - accuracy: 0.96 - ETA: 2s - loss: 0.0938 - accuracy: 0.96 - ETA: 2s - loss: 0.0935 - accuracy: 0.96 - ETA: 2s - loss: 0.0933 - accuracy: 0.96 - ETA: 2s - loss: 0.0920 - accuracy: 0.96 - ETA: 2s - loss: 0.0913 - accuracy: 0.96 - ETA: 1s - loss: 0.0916 - accuracy: 0.96 - ETA: 1s - loss: 0.0906 - accuracy: 0.96 - ETA: 1s - loss: 0.0924 - accuracy: 0.96 - ETA: 1s - loss: 0.0918 - accuracy: 0.96 - ETA: 1s - loss: 0.0922 - accuracy: 0.96 - ETA: 1s - loss: 0.0912 - accuracy: 0.96 - ETA: 1s - loss: 0.0967 - accuracy: 0.96 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 1s - loss: 0.0964 - accuracy: 0.96 - ETA: 1s - loss: 0.0951 - accuracy: 0.96 - ETA: 1s - loss: 0.0947 - accuracy: 0.96 - ETA: 1s - loss: 0.0972 - accuracy: 0.96 - ETA: 1s - loss: 0.0983 - accuracy: 0.96 - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - ETA: 0s - loss: 0.1003 - accuracy: 0.96 - ETA: 0s - loss: 0.1003 - accuracy: 0.96 - ETA: 0s - loss: 0.1010 - accuracy: 0.96 - ETA: 0s - loss: 0.1015 - accuracy: 0.96 - ETA: 0s - loss: 0.1039 - accuracy: 0.95 - ETA: 0s - loss: 0.1035 - accuracy: 0.95 - ETA: 0s - loss: 0.1029 - accuracy: 0.96 - ETA: 0s - loss: 0.1033 - accuracy: 0.95 - ETA: 0s - loss: 0.1032 - accuracy: 0.95 - ETA: 0s - loss: 0.1056 - accuracy: 0.95 - 5s 44ms/step - loss: 0.1054 - accuracy: 0.9586 - val_loss: 0.1061 - val_accuracy: 0.9550\n",
      "Epoch 19/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 1.00 - ETA: 2s - loss: 0.0476 - accuracy: 0.98 - ETA: 2s - loss: 0.0562 - accuracy: 0.98 - ETA: 3s - loss: 0.0642 - accuracy: 0.97 - ETA: 3s - loss: 0.0682 - accuracy: 0.97 - ETA: 3s - loss: 0.0809 - accuracy: 0.96 - ETA: 3s - loss: 0.0975 - accuracy: 0.96 - ETA: 3s - loss: 0.0943 - accuracy: 0.96 - ETA: 3s - loss: 0.0978 - accuracy: 0.96 - ETA: 3s - loss: 0.0956 - accuracy: 0.96 - ETA: 3s - loss: 0.1019 - accuracy: 0.96 - ETA: 3s - loss: 0.0983 - accuracy: 0.96 - ETA: 3s - loss: 0.0974 - accuracy: 0.96 - ETA: 2s - loss: 0.0933 - accuracy: 0.96 - ETA: 2s - loss: 0.0909 - accuracy: 0.96 - ETA: 2s - loss: 0.0933 - accuracy: 0.96 - ETA: 2s - loss: 0.0920 - accuracy: 0.96 - ETA: 2s - loss: 0.0904 - accuracy: 0.96 - ETA: 2s - loss: 0.0888 - accuracy: 0.96 - ETA: 2s - loss: 0.0904 - accuracy: 0.96 - ETA: 2s - loss: 0.0903 - accuracy: 0.96 - ETA: 2s - loss: 0.0904 - accuracy: 0.96 - ETA: 2s - loss: 0.0968 - accuracy: 0.96 - ETA: 2s - loss: 0.0993 - accuracy: 0.96 - ETA: 2s - loss: 0.0982 - accuracy: 0.96 - ETA: 2s - loss: 0.0973 - accuracy: 0.96 - ETA: 2s - loss: 0.0955 - accuracy: 0.96 - ETA: 2s - loss: 0.0954 - accuracy: 0.96 - ETA: 2s - loss: 0.0950 - accuracy: 0.96 - ETA: 2s - loss: 0.0933 - accuracy: 0.96 - ETA: 2s - loss: 0.0922 - accuracy: 0.96 - ETA: 2s - loss: 0.0913 - accuracy: 0.97 - ETA: 1s - loss: 0.0891 - accuracy: 0.97 - ETA: 1s - loss: 0.0896 - accuracy: 0.97 - ETA: 1s - loss: 0.0893 - accuracy: 0.97 - ETA: 1s - loss: 0.0893 - accuracy: 0.97 - ETA: 1s - loss: 0.0899 - accuracy: 0.97 - ETA: 1s - loss: 0.0897 - accuracy: 0.97 - ETA: 1s - loss: 0.0899 - accuracy: 0.97 - ETA: 1s - loss: 0.0894 - accuracy: 0.97 - ETA: 1s - loss: 0.0903 - accuracy: 0.97 - ETA: 1s - loss: 0.0906 - accuracy: 0.96 - ETA: 1s - loss: 0.0913 - accuracy: 0.96 - ETA: 1s - loss: 0.0911 - accuracy: 0.96 - ETA: 1s - loss: 0.0901 - accuracy: 0.96 - ETA: 1s - loss: 0.0906 - accuracy: 0.96 - ETA: 1s - loss: 0.0902 - accuracy: 0.96 - ETA: 0s - loss: 0.0910 - accuracy: 0.96 - ETA: 0s - loss: 0.0906 - accuracy: 0.96 - ETA: 0s - loss: 0.0900 - accuracy: 0.96 - ETA: 0s - loss: 0.0895 - accuracy: 0.96 - ETA: 0s - loss: 0.0900 - accuracy: 0.96 - ETA: 0s - loss: 0.0899 - accuracy: 0.96 - ETA: 0s - loss: 0.0886 - accuracy: 0.96 - ETA: 0s - loss: 0.0914 - accuracy: 0.96 - ETA: 0s - loss: 0.0929 - accuracy: 0.96 - ETA: 0s - loss: 0.0917 - accuracy: 0.96 - ETA: 0s - loss: 0.0908 - accuracy: 0.96 - ETA: 0s - loss: 0.0908 - accuracy: 0.96 - ETA: 0s - loss: 0.0913 - accuracy: 0.96 - 4s 41ms/step - loss: 0.0909 - accuracy: 0.9671 - val_loss: 0.1152 - val_accuracy: 0.9513\n",
      "Epoch 20/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.96 - ETA: 2s - loss: 0.1303 - accuracy: 0.95 - ETA: 2s - loss: 0.0941 - accuracy: 0.96 - ETA: 3s - loss: 0.0907 - accuracy: 0.97 - ETA: 3s - loss: 0.1118 - accuracy: 0.95 - ETA: 3s - loss: 0.1094 - accuracy: 0.95 - ETA: 3s - loss: 0.1181 - accuracy: 0.95 - ETA: 3s - loss: 0.1474 - accuracy: 0.94 - ETA: 3s - loss: 0.1385 - accuracy: 0.94 - ETA: 3s - loss: 0.1286 - accuracy: 0.95 - ETA: 3s - loss: 0.1233 - accuracy: 0.95 - ETA: 3s - loss: 0.1156 - accuracy: 0.95 - ETA: 3s - loss: 0.1087 - accuracy: 0.95 - ETA: 2s - loss: 0.1103 - accuracy: 0.95 - ETA: 2s - loss: 0.1097 - accuracy: 0.95 - ETA: 2s - loss: 0.1089 - accuracy: 0.95 - ETA: 2s - loss: 0.1071 - accuracy: 0.95 - ETA: 2s - loss: 0.1037 - accuracy: 0.95 - ETA: 2s - loss: 0.1018 - accuracy: 0.96 - ETA: 2s - loss: 0.1000 - accuracy: 0.96 - ETA: 2s - loss: 0.0983 - accuracy: 0.96 - ETA: 2s - loss: 0.0993 - accuracy: 0.96 - ETA: 2s - loss: 0.0982 - accuracy: 0.96 - ETA: 2s - loss: 0.0972 - accuracy: 0.96 - ETA: 2s - loss: 0.0963 - accuracy: 0.96 - ETA: 2s - loss: 0.0975 - accuracy: 0.96 - ETA: 2s - loss: 0.0972 - accuracy: 0.96 - ETA: 2s - loss: 0.1026 - accuracy: 0.96 - ETA: 2s - loss: 0.1012 - accuracy: 0.96 - ETA: 1s - loss: 0.1019 - accuracy: 0.96 - ETA: 1s - loss: 0.1017 - accuracy: 0.96 - ETA: 1s - loss: 0.0998 - accuracy: 0.96 - ETA: 1s - loss: 0.0984 - accuracy: 0.96 - ETA: 1s - loss: 0.0975 - accuracy: 0.96 - ETA: 1s - loss: 0.0952 - accuracy: 0.96 - ETA: 1s - loss: 0.0950 - accuracy: 0.96 - ETA: 1s - loss: 0.0957 - accuracy: 0.96 - ETA: 1s - loss: 0.0963 - accuracy: 0.96 - ETA: 1s - loss: 0.0968 - accuracy: 0.96 - ETA: 1s - loss: 0.0954 - accuracy: 0.96 - ETA: 1s - loss: 0.0960 - accuracy: 0.96 - ETA: 1s - loss: 0.0954 - accuracy: 0.96 - ETA: 1s - loss: 0.0948 - accuracy: 0.96 - ETA: 1s - loss: 0.0952 - accuracy: 0.96 - ETA: 1s - loss: 0.0938 - accuracy: 0.96 - ETA: 0s - loss: 0.0927 - accuracy: 0.96 - ETA: 0s - loss: 0.0931 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0951 - accuracy: 0.96 - ETA: 0s - loss: 0.0959 - accuracy: 0.96 - ETA: 0s - loss: 0.0955 - accuracy: 0.96 - ETA: 0s - loss: 0.0946 - accuracy: 0.96 - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - ETA: 0s - loss: 0.0937 - accuracy: 0.96 - ETA: 0s - loss: 0.0937 - accuracy: 0.96 - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - ETA: 0s - loss: 0.0946 - accuracy: 0.96 - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - 4s 41ms/step - loss: 0.0933 - accuracy: 0.9659 - val_loss: 0.1147 - val_accuracy: 0.9513\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - ETA: 2s - loss: 0.0783 - accuracy: 0.96 - ETA: 3s - loss: 0.0742 - accuracy: 0.97 - ETA: 3s - loss: 0.0807 - accuracy: 0.97 - ETA: 3s - loss: 0.0800 - accuracy: 0.97 - ETA: 3s - loss: 0.0781 - accuracy: 0.97 - ETA: 3s - loss: 0.0731 - accuracy: 0.97 - ETA: 3s - loss: 0.0696 - accuracy: 0.97 - ETA: 3s - loss: 0.0692 - accuracy: 0.97 - ETA: 3s - loss: 0.0760 - accuracy: 0.96 - ETA: 3s - loss: 0.0766 - accuracy: 0.96 - ETA: 3s - loss: 0.0764 - accuracy: 0.96 - ETA: 3s - loss: 0.0842 - accuracy: 0.96 - ETA: 3s - loss: 0.0833 - accuracy: 0.96 - ETA: 2s - loss: 0.0861 - accuracy: 0.96 - ETA: 2s - loss: 0.0847 - accuracy: 0.96 - ETA: 2s - loss: 0.0812 - accuracy: 0.96 - ETA: 2s - loss: 0.0788 - accuracy: 0.96 - ETA: 2s - loss: 0.0789 - accuracy: 0.96 - ETA: 2s - loss: 0.0812 - accuracy: 0.96 - ETA: 2s - loss: 0.0797 - accuracy: 0.96 - ETA: 2s - loss: 0.0792 - accuracy: 0.96 - ETA: 2s - loss: 0.0821 - accuracy: 0.96 - ETA: 2s - loss: 0.0823 - accuracy: 0.96 - ETA: 2s - loss: 0.0812 - accuracy: 0.96 - ETA: 2s - loss: 0.0800 - accuracy: 0.96 - ETA: 2s - loss: 0.0805 - accuracy: 0.96 - ETA: 2s - loss: 0.0797 - accuracy: 0.97 - ETA: 2s - loss: 0.0797 - accuracy: 0.97 - ETA: 2s - loss: 0.0787 - accuracy: 0.97 - ETA: 2s - loss: 0.0778 - accuracy: 0.97 - ETA: 1s - loss: 0.0771 - accuracy: 0.97 - ETA: 1s - loss: 0.0759 - accuracy: 0.97 - ETA: 1s - loss: 0.0761 - accuracy: 0.97 - ETA: 1s - loss: 0.0762 - accuracy: 0.97 - ETA: 1s - loss: 0.0767 - accuracy: 0.97 - ETA: 1s - loss: 0.0769 - accuracy: 0.97 - ETA: 1s - loss: 0.0781 - accuracy: 0.97 - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 1s - loss: 0.0780 - accuracy: 0.97 - ETA: 1s - loss: 0.0783 - accuracy: 0.97 - ETA: 1s - loss: 0.0789 - accuracy: 0.97 - ETA: 1s - loss: 0.0783 - accuracy: 0.97 - ETA: 1s - loss: 0.0780 - accuracy: 0.97 - ETA: 1s - loss: 0.0784 - accuracy: 0.97 - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 1s - loss: 0.0771 - accuracy: 0.97 - ETA: 1s - loss: 0.0773 - accuracy: 0.97 - ETA: 0s - loss: 0.0791 - accuracy: 0.96 - ETA: 0s - loss: 0.0794 - accuracy: 0.96 - ETA: 0s - loss: 0.0800 - accuracy: 0.96 - ETA: 0s - loss: 0.0819 - accuracy: 0.96 - ETA: 0s - loss: 0.0830 - accuracy: 0.96 - ETA: 0s - loss: 0.0825 - accuracy: 0.96 - ETA: 0s - loss: 0.0821 - accuracy: 0.96 - ETA: 0s - loss: 0.0834 - accuracy: 0.96 - ETA: 0s - loss: 0.0829 - accuracy: 0.96 - ETA: 0s - loss: 0.0824 - accuracy: 0.96 - ETA: 0s - loss: 0.0819 - accuracy: 0.96 - ETA: 0s - loss: 0.0820 - accuracy: 0.96 - ETA: 0s - loss: 0.0814 - accuracy: 0.96 - ETA: 0s - loss: 0.0817 - accuracy: 0.96 - ETA: 0s - loss: 0.0819 - accuracy: 0.96 - 4s 41ms/step - loss: 0.0816 - accuracy: 0.9692 - val_loss: 0.1058 - val_accuracy: 0.9562\n",
      "Epoch 22/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - ETA: 2s - loss: 0.0450 - accuracy: 0.97 - ETA: 2s - loss: 0.0726 - accuracy: 0.96 - ETA: 3s - loss: 0.0648 - accuracy: 0.97 - ETA: 3s - loss: 0.0654 - accuracy: 0.97 - ETA: 3s - loss: 0.0681 - accuracy: 0.97 - ETA: 3s - loss: 0.0720 - accuracy: 0.97 - ETA: 3s - loss: 0.0726 - accuracy: 0.97 - ETA: 3s - loss: 0.0651 - accuracy: 0.97 - ETA: 3s - loss: 0.0647 - accuracy: 0.97 - ETA: 3s - loss: 0.0691 - accuracy: 0.97 - ETA: 3s - loss: 0.0713 - accuracy: 0.97 - ETA: 3s - loss: 0.0727 - accuracy: 0.97 - ETA: 3s - loss: 0.0742 - accuracy: 0.97 - ETA: 2s - loss: 0.0762 - accuracy: 0.97 - ETA: 2s - loss: 0.0753 - accuracy: 0.97 - ETA: 2s - loss: 0.0738 - accuracy: 0.97 - ETA: 2s - loss: 0.0741 - accuracy: 0.97 - ETA: 2s - loss: 0.0743 - accuracy: 0.97 - ETA: 2s - loss: 0.0773 - accuracy: 0.97 - ETA: 2s - loss: 0.0792 - accuracy: 0.96 - ETA: 2s - loss: 0.0779 - accuracy: 0.97 - ETA: 2s - loss: 0.0776 - accuracy: 0.96 - ETA: 2s - loss: 0.0804 - accuracy: 0.96 - ETA: 2s - loss: 0.0809 - accuracy: 0.96 - ETA: 2s - loss: 0.0825 - accuracy: 0.96 - ETA: 2s - loss: 0.0823 - accuracy: 0.96 - ETA: 2s - loss: 0.0844 - accuracy: 0.96 - ETA: 2s - loss: 0.0856 - accuracy: 0.96 - ETA: 1s - loss: 0.0851 - accuracy: 0.96 - ETA: 1s - loss: 0.0844 - accuracy: 0.96 - ETA: 1s - loss: 0.0842 - accuracy: 0.96 - ETA: 1s - loss: 0.0848 - accuracy: 0.96 - ETA: 1s - loss: 0.0840 - accuracy: 0.96 - ETA: 1s - loss: 0.0855 - accuracy: 0.96 - ETA: 1s - loss: 0.0862 - accuracy: 0.96 - ETA: 1s - loss: 0.0873 - accuracy: 0.96 - ETA: 1s - loss: 0.0850 - accuracy: 0.96 - ETA: 1s - loss: 0.0866 - accuracy: 0.96 - ETA: 1s - loss: 0.0864 - accuracy: 0.96 - ETA: 1s - loss: 0.0857 - accuracy: 0.96 - ETA: 1s - loss: 0.0869 - accuracy: 0.96 - ETA: 1s - loss: 0.0864 - accuracy: 0.96 - ETA: 1s - loss: 0.0855 - accuracy: 0.96 - ETA: 1s - loss: 0.0848 - accuracy: 0.96 - ETA: 1s - loss: 0.0859 - accuracy: 0.96 - ETA: 0s - loss: 0.0867 - accuracy: 0.96 - ETA: 0s - loss: 0.0854 - accuracy: 0.96 - ETA: 0s - loss: 0.0850 - accuracy: 0.96 - ETA: 0s - loss: 0.0845 - accuracy: 0.96 - ETA: 0s - loss: 0.0854 - accuracy: 0.96 - ETA: 0s - loss: 0.0845 - accuracy: 0.96 - ETA: 0s - loss: 0.0848 - accuracy: 0.96 - ETA: 0s - loss: 0.0849 - accuracy: 0.96 - ETA: 0s - loss: 0.0846 - accuracy: 0.96 - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - ETA: 0s - loss: 0.0856 - accuracy: 0.96 - ETA: 0s - loss: 0.0855 - accuracy: 0.96 - ETA: 0s - loss: 0.0854 - accuracy: 0.96 - ETA: 0s - loss: 0.0851 - accuracy: 0.96 - 4s 41ms/step - loss: 0.0852 - accuracy: 0.9680 - val_loss: 0.1031 - val_accuracy: 0.9635\n",
      "Epoch 23/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 1.00 - ETA: 2s - loss: 0.0359 - accuracy: 1.00 - ETA: 2s - loss: 0.0469 - accuracy: 0.99 - ETA: 3s - loss: 0.0465 - accuracy: 0.98 - ETA: 3s - loss: 0.0528 - accuracy: 0.98 - ETA: 3s - loss: 0.0576 - accuracy: 0.98 - ETA: 3s - loss: 0.0590 - accuracy: 0.98 - ETA: 3s - loss: 0.0675 - accuracy: 0.98 - ETA: 3s - loss: 0.0753 - accuracy: 0.97 - ETA: 3s - loss: 0.0808 - accuracy: 0.97 - ETA: 3s - loss: 0.0806 - accuracy: 0.97 - ETA: 3s - loss: 0.0793 - accuracy: 0.97 - ETA: 3s - loss: 0.0771 - accuracy: 0.97 - ETA: 3s - loss: 0.0811 - accuracy: 0.97 - ETA: 2s - loss: 0.0777 - accuracy: 0.97 - ETA: 2s - loss: 0.0767 - accuracy: 0.97 - ETA: 2s - loss: 0.0784 - accuracy: 0.97 - ETA: 2s - loss: 0.0778 - accuracy: 0.97 - ETA: 2s - loss: 0.0795 - accuracy: 0.97 - ETA: 2s - loss: 0.0799 - accuracy: 0.97 - ETA: 2s - loss: 0.0785 - accuracy: 0.97 - ETA: 2s - loss: 0.0808 - accuracy: 0.97 - ETA: 2s - loss: 0.0845 - accuracy: 0.96 - ETA: 2s - loss: 0.0836 - accuracy: 0.97 - ETA: 2s - loss: 0.0820 - accuracy: 0.97 - ETA: 2s - loss: 0.0828 - accuracy: 0.97 - ETA: 2s - loss: 0.0815 - accuracy: 0.97 - ETA: 2s - loss: 0.0821 - accuracy: 0.97 - ETA: 2s - loss: 0.0821 - accuracy: 0.97 - ETA: 2s - loss: 0.0809 - accuracy: 0.97 - ETA: 1s - loss: 0.0811 - accuracy: 0.97 - ETA: 1s - loss: 0.0823 - accuracy: 0.97 - ETA: 1s - loss: 0.0827 - accuracy: 0.97 - ETA: 1s - loss: 0.0817 - accuracy: 0.97 - ETA: 1s - loss: 0.0808 - accuracy: 0.97 - ETA: 1s - loss: 0.0792 - accuracy: 0.97 - ETA: 1s - loss: 0.0796 - accuracy: 0.97 - ETA: 1s - loss: 0.0779 - accuracy: 0.97 - ETA: 1s - loss: 0.0776 - accuracy: 0.97 - ETA: 1s - loss: 0.0795 - accuracy: 0.97 - ETA: 1s - loss: 0.0791 - accuracy: 0.97 - ETA: 1s - loss: 0.0793 - accuracy: 0.97 - ETA: 1s - loss: 0.0791 - accuracy: 0.97 - ETA: 1s - loss: 0.0800 - accuracy: 0.97 - ETA: 1s - loss: 0.0795 - accuracy: 0.97 - ETA: 0s - loss: 0.0798 - accuracy: 0.97 - ETA: 0s - loss: 0.0801 - accuracy: 0.97 - ETA: 0s - loss: 0.0803 - accuracy: 0.97 - ETA: 0s - loss: 0.0797 - accuracy: 0.97 - ETA: 0s - loss: 0.0801 - accuracy: 0.97 - ETA: 0s - loss: 0.0810 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0810 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0806 - accuracy: 0.97 - ETA: 0s - loss: 0.0805 - accuracy: 0.97 - ETA: 0s - loss: 0.0804 - accuracy: 0.97 - ETA: 0s - loss: 0.0800 - accuracy: 0.97 - 4s 41ms/step - loss: 0.0797 - accuracy: 0.9726 - val_loss: 0.1122 - val_accuracy: 0.9562\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.00 - ETA: 2s - loss: 0.0944 - accuracy: 0.97 - ETA: 2s - loss: 0.0925 - accuracy: 0.98 - ETA: 3s - loss: 0.0789 - accuracy: 0.98 - ETA: 3s - loss: 0.0696 - accuracy: 0.98 - ETA: 3s - loss: 0.0724 - accuracy: 0.98 - ETA: 3s - loss: 0.0665 - accuracy: 0.98 - ETA: 3s - loss: 0.0600 - accuracy: 0.98 - ETA: 3s - loss: 0.0574 - accuracy: 0.98 - ETA: 3s - loss: 0.0565 - accuracy: 0.98 - ETA: 3s - loss: 0.0567 - accuracy: 0.98 - ETA: 3s - loss: 0.0672 - accuracy: 0.98 - ETA: 3s - loss: 0.0671 - accuracy: 0.98 - ETA: 2s - loss: 0.0673 - accuracy: 0.98 - ETA: 2s - loss: 0.0660 - accuracy: 0.98 - ETA: 2s - loss: 0.0651 - accuracy: 0.98 - ETA: 2s - loss: 0.0640 - accuracy: 0.98 - ETA: 2s - loss: 0.0671 - accuracy: 0.98 - ETA: 2s - loss: 0.0664 - accuracy: 0.98 - ETA: 2s - loss: 0.0660 - accuracy: 0.98 - ETA: 2s - loss: 0.0646 - accuracy: 0.98 - ETA: 2s - loss: 0.0737 - accuracy: 0.97 - ETA: 2s - loss: 0.0755 - accuracy: 0.97 - ETA: 2s - loss: 0.0744 - accuracy: 0.97 - ETA: 2s - loss: 0.0746 - accuracy: 0.97 - ETA: 2s - loss: 0.0731 - accuracy: 0.97 - ETA: 2s - loss: 0.0736 - accuracy: 0.97 - ETA: 2s - loss: 0.0733 - accuracy: 0.97 - ETA: 2s - loss: 0.0724 - accuracy: 0.97 - ETA: 2s - loss: 0.0717 - accuracy: 0.97 - ETA: 2s - loss: 0.0730 - accuracy: 0.97 - ETA: 2s - loss: 0.0722 - accuracy: 0.97 - ETA: 1s - loss: 0.0712 - accuracy: 0.97 - ETA: 1s - loss: 0.0761 - accuracy: 0.97 - ETA: 1s - loss: 0.0779 - accuracy: 0.97 - ETA: 1s - loss: 0.0788 - accuracy: 0.97 - ETA: 1s - loss: 0.0780 - accuracy: 0.97 - ETA: 1s - loss: 0.0791 - accuracy: 0.97 - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 1s - loss: 0.0773 - accuracy: 0.97 - ETA: 1s - loss: 0.0792 - accuracy: 0.97 - ETA: 1s - loss: 0.0801 - accuracy: 0.97 - ETA: 1s - loss: 0.0831 - accuracy: 0.97 - ETA: 1s - loss: 0.0834 - accuracy: 0.97 - ETA: 1s - loss: 0.0841 - accuracy: 0.96 - ETA: 1s - loss: 0.0847 - accuracy: 0.96 - ETA: 1s - loss: 0.0841 - accuracy: 0.96 - ETA: 1s - loss: 0.0845 - accuracy: 0.96 - ETA: 0s - loss: 0.0836 - accuracy: 0.96 - ETA: 0s - loss: 0.0836 - accuracy: 0.96 - ETA: 0s - loss: 0.0824 - accuracy: 0.96 - ETA: 0s - loss: 0.0827 - accuracy: 0.96 - ETA: 0s - loss: 0.0822 - accuracy: 0.96 - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - ETA: 0s - loss: 0.0809 - accuracy: 0.97 - ETA: 0s - loss: 0.0813 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0800 - accuracy: 0.97 - ETA: 0s - loss: 0.0797 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0797 - accuracy: 0.97 - ETA: 0s - loss: 0.0803 - accuracy: 0.97 - 4s 41ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.0997 - val_accuracy: 0.9611\n",
      "Epoch 25/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.00 - ETA: 2s - loss: 0.0619 - accuracy: 0.97 - ETA: 2s - loss: 0.0594 - accuracy: 0.98 - ETA: 3s - loss: 0.0480 - accuracy: 0.98 - ETA: 3s - loss: 0.0546 - accuracy: 0.98 - ETA: 3s - loss: 0.0640 - accuracy: 0.98 - ETA: 3s - loss: 0.0654 - accuracy: 0.97 - ETA: 3s - loss: 0.0619 - accuracy: 0.97 - ETA: 3s - loss: 0.0617 - accuracy: 0.98 - ETA: 3s - loss: 0.0610 - accuracy: 0.98 - ETA: 3s - loss: 0.0688 - accuracy: 0.97 - ETA: 3s - loss: 0.0733 - accuracy: 0.97 - ETA: 2s - loss: 0.0693 - accuracy: 0.97 - ETA: 2s - loss: 0.0678 - accuracy: 0.97 - ETA: 2s - loss: 0.0695 - accuracy: 0.97 - ETA: 2s - loss: 0.0677 - accuracy: 0.97 - ETA: 2s - loss: 0.0666 - accuracy: 0.97 - ETA: 2s - loss: 0.0681 - accuracy: 0.97 - ETA: 2s - loss: 0.0677 - accuracy: 0.97 - ETA: 2s - loss: 0.0667 - accuracy: 0.97 - ETA: 2s - loss: 0.0673 - accuracy: 0.97 - ETA: 2s - loss: 0.0657 - accuracy: 0.97 - ETA: 2s - loss: 0.0666 - accuracy: 0.97 - ETA: 2s - loss: 0.0669 - accuracy: 0.97 - ETA: 2s - loss: 0.0654 - accuracy: 0.97 - ETA: 2s - loss: 0.0661 - accuracy: 0.97 - ETA: 2s - loss: 0.0641 - accuracy: 0.97 - ETA: 2s - loss: 0.0634 - accuracy: 0.97 - ETA: 2s - loss: 0.0627 - accuracy: 0.97 - ETA: 1s - loss: 0.0625 - accuracy: 0.97 - ETA: 1s - loss: 0.0625 - accuracy: 0.97 - ETA: 1s - loss: 0.0631 - accuracy: 0.97 - ETA: 1s - loss: 0.0629 - accuracy: 0.97 - ETA: 1s - loss: 0.0626 - accuracy: 0.97 - ETA: 1s - loss: 0.0629 - accuracy: 0.97 - ETA: 1s - loss: 0.0622 - accuracy: 0.97 - ETA: 1s - loss: 0.0632 - accuracy: 0.97 - ETA: 1s - loss: 0.0638 - accuracy: 0.97 - ETA: 1s - loss: 0.0633 - accuracy: 0.97 - ETA: 1s - loss: 0.0631 - accuracy: 0.97 - ETA: 1s - loss: 0.0627 - accuracy: 0.97 - ETA: 1s - loss: 0.0633 - accuracy: 0.97 - ETA: 1s - loss: 0.0637 - accuracy: 0.97 - ETA: 1s - loss: 0.0634 - accuracy: 0.97 - ETA: 1s - loss: 0.0635 - accuracy: 0.97 - ETA: 0s - loss: 0.0645 - accuracy: 0.97 - ETA: 0s - loss: 0.0653 - accuracy: 0.97 - ETA: 0s - loss: 0.0642 - accuracy: 0.97 - ETA: 0s - loss: 0.0660 - accuracy: 0.97 - ETA: 0s - loss: 0.0659 - accuracy: 0.97 - ETA: 0s - loss: 0.0662 - accuracy: 0.97 - ETA: 0s - loss: 0.0663 - accuracy: 0.97 - ETA: 0s - loss: 0.0670 - accuracy: 0.97 - ETA: 0s - loss: 0.0679 - accuracy: 0.97 - ETA: 0s - loss: 0.0677 - accuracy: 0.97 - ETA: 0s - loss: 0.0675 - accuracy: 0.97 - ETA: 0s - loss: 0.0674 - accuracy: 0.97 - ETA: 0s - loss: 0.0671 - accuracy: 0.97 - ETA: 0s - loss: 0.0676 - accuracy: 0.97 - ETA: 0s - loss: 0.0687 - accuracy: 0.97 - 4s 41ms/step - loss: 0.0687 - accuracy: 0.9753 - val_loss: 0.1092 - val_accuracy: 0.9513\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.96 - ETA: 2s - loss: 0.0759 - accuracy: 0.96 - ETA: 2s - loss: 0.0608 - accuracy: 0.98 - ETA: 2s - loss: 0.0623 - accuracy: 0.97 - ETA: 3s - loss: 0.0713 - accuracy: 0.97 - ETA: 3s - loss: 0.0800 - accuracy: 0.96 - ETA: 3s - loss: 0.0777 - accuracy: 0.96 - ETA: 3s - loss: 0.0809 - accuracy: 0.96 - ETA: 3s - loss: 0.0774 - accuracy: 0.96 - ETA: 3s - loss: 0.0748 - accuracy: 0.96 - ETA: 3s - loss: 0.0742 - accuracy: 0.96 - ETA: 3s - loss: 0.0730 - accuracy: 0.96 - ETA: 3s - loss: 0.0742 - accuracy: 0.96 - ETA: 3s - loss: 0.0732 - accuracy: 0.96 - ETA: 3s - loss: 0.0702 - accuracy: 0.96 - ETA: 3s - loss: 0.0701 - accuracy: 0.96 - ETA: 3s - loss: 0.0700 - accuracy: 0.96 - ETA: 3s - loss: 0.0692 - accuracy: 0.96 - ETA: 3s - loss: 0.0693 - accuracy: 0.96 - ETA: 2s - loss: 0.0693 - accuracy: 0.96 - ETA: 2s - loss: 0.0700 - accuracy: 0.96 - ETA: 2s - loss: 0.0694 - accuracy: 0.96 - ETA: 2s - loss: 0.0699 - accuracy: 0.97 - ETA: 2s - loss: 0.0695 - accuracy: 0.97 - ETA: 2s - loss: 0.0683 - accuracy: 0.97 - ETA: 2s - loss: 0.0692 - accuracy: 0.97 - ETA: 2s - loss: 0.0681 - accuracy: 0.97 - ETA: 2s - loss: 0.0704 - accuracy: 0.97 - ETA: 2s - loss: 0.0696 - accuracy: 0.97 - ETA: 2s - loss: 0.0689 - accuracy: 0.97 - ETA: 2s - loss: 0.0686 - accuracy: 0.97 - ETA: 2s - loss: 0.0683 - accuracy: 0.97 - ETA: 2s - loss: 0.0672 - accuracy: 0.97 - ETA: 2s - loss: 0.0664 - accuracy: 0.97 - ETA: 2s - loss: 0.0655 - accuracy: 0.97 - ETA: 2s - loss: 0.0640 - accuracy: 0.97 - ETA: 2s - loss: 0.0632 - accuracy: 0.97 - ETA: 2s - loss: 0.0626 - accuracy: 0.97 - ETA: 2s - loss: 0.0618 - accuracy: 0.97 - ETA: 2s - loss: 0.0617 - accuracy: 0.97 - ETA: 1s - loss: 0.0609 - accuracy: 0.97 - ETA: 1s - loss: 0.0613 - accuracy: 0.97 - ETA: 1s - loss: 0.0606 - accuracy: 0.97 - ETA: 1s - loss: 0.0601 - accuracy: 0.97 - ETA: 1s - loss: 0.0615 - accuracy: 0.97 - ETA: 1s - loss: 0.0616 - accuracy: 0.97 - ETA: 1s - loss: 0.0608 - accuracy: 0.97 - ETA: 1s - loss: 0.0628 - accuracy: 0.97 - ETA: 1s - loss: 0.0622 - accuracy: 0.97 - ETA: 1s - loss: 0.0610 - accuracy: 0.97 - ETA: 1s - loss: 0.0659 - accuracy: 0.97 - ETA: 1s - loss: 0.0664 - accuracy: 0.97 - ETA: 1s - loss: 0.0662 - accuracy: 0.97 - ETA: 1s - loss: 0.0663 - accuracy: 0.97 - ETA: 0s - loss: 0.0673 - accuracy: 0.97 - ETA: 0s - loss: 0.0676 - accuracy: 0.97 - ETA: 0s - loss: 0.0687 - accuracy: 0.97 - ETA: 0s - loss: 0.0695 - accuracy: 0.97 - ETA: 0s - loss: 0.0699 - accuracy: 0.97 - ETA: 0s - loss: 0.0691 - accuracy: 0.97 - ETA: 0s - loss: 0.0705 - accuracy: 0.97 - ETA: 0s - loss: 0.0700 - accuracy: 0.97 - ETA: 0s - loss: 0.0695 - accuracy: 0.97 - ETA: 0s - loss: 0.0694 - accuracy: 0.97 - ETA: 0s - loss: 0.0695 - accuracy: 0.97 - ETA: 0s - loss: 0.0693 - accuracy: 0.97 - ETA: 0s - loss: 0.0699 - accuracy: 0.97 - ETA: 0s - loss: 0.0704 - accuracy: 0.97 - 5s 46ms/step - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.0951 - val_accuracy: 0.9611\n",
      "Epoch 27/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.96 - ETA: 2s - loss: 0.1434 - accuracy: 0.95 - ETA: 3s - loss: 0.1041 - accuracy: 0.96 - ETA: 3s - loss: 0.1022 - accuracy: 0.96 - ETA: 3s - loss: 0.0979 - accuracy: 0.96 - ETA: 3s - loss: 0.1018 - accuracy: 0.96 - ETA: 3s - loss: 0.1082 - accuracy: 0.96 - ETA: 3s - loss: 0.1020 - accuracy: 0.96 - ETA: 3s - loss: 0.1054 - accuracy: 0.96 - ETA: 3s - loss: 0.0956 - accuracy: 0.96 - ETA: 3s - loss: 0.0904 - accuracy: 0.96 - ETA: 3s - loss: 0.0918 - accuracy: 0.96 - ETA: 3s - loss: 0.0901 - accuracy: 0.96 - ETA: 3s - loss: 0.0907 - accuracy: 0.96 - ETA: 2s - loss: 0.0862 - accuracy: 0.97 - ETA: 2s - loss: 0.0875 - accuracy: 0.96 - ETA: 2s - loss: 0.0896 - accuracy: 0.96 - ETA: 2s - loss: 0.0923 - accuracy: 0.96 - ETA: 2s - loss: 0.0901 - accuracy: 0.96 - ETA: 2s - loss: 0.0892 - accuracy: 0.96 - ETA: 2s - loss: 0.0882 - accuracy: 0.96 - ETA: 2s - loss: 0.0870 - accuracy: 0.96 - ETA: 2s - loss: 0.0883 - accuracy: 0.96 - ETA: 2s - loss: 0.0852 - accuracy: 0.97 - ETA: 2s - loss: 0.0844 - accuracy: 0.97 - ETA: 2s - loss: 0.0854 - accuracy: 0.96 - ETA: 2s - loss: 0.0847 - accuracy: 0.96 - ETA: 2s - loss: 0.0834 - accuracy: 0.97 - ETA: 2s - loss: 0.0821 - accuracy: 0.97 - ETA: 2s - loss: 0.0808 - accuracy: 0.97 - ETA: 1s - loss: 0.0830 - accuracy: 0.97 - ETA: 1s - loss: 0.0817 - accuracy: 0.97 - ETA: 1s - loss: 0.0811 - accuracy: 0.97 - ETA: 1s - loss: 0.0802 - accuracy: 0.97 - ETA: 1s - loss: 0.0805 - accuracy: 0.97 - ETA: 1s - loss: 0.0796 - accuracy: 0.97 - ETA: 1s - loss: 0.0788 - accuracy: 0.97 - ETA: 1s - loss: 0.0796 - accuracy: 0.97 - ETA: 1s - loss: 0.0809 - accuracy: 0.97 - ETA: 1s - loss: 0.0804 - accuracy: 0.97 - ETA: 1s - loss: 0.0799 - accuracy: 0.97 - ETA: 1s - loss: 0.0806 - accuracy: 0.97 - ETA: 1s - loss: 0.0800 - accuracy: 0.96 - ETA: 1s - loss: 0.0790 - accuracy: 0.97 - ETA: 1s - loss: 0.0786 - accuracy: 0.97 - ETA: 0s - loss: 0.0781 - accuracy: 0.97 - ETA: 0s - loss: 0.0781 - accuracy: 0.97 - ETA: 0s - loss: 0.0774 - accuracy: 0.97 - ETA: 0s - loss: 0.0774 - accuracy: 0.97 - ETA: 0s - loss: 0.0766 - accuracy: 0.97 - ETA: 0s - loss: 0.0766 - accuracy: 0.97 - ETA: 0s - loss: 0.0763 - accuracy: 0.97 - ETA: 0s - loss: 0.0760 - accuracy: 0.97 - ETA: 0s - loss: 0.0752 - accuracy: 0.97 - ETA: 0s - loss: 0.0747 - accuracy: 0.97 - ETA: 0s - loss: 0.0755 - accuracy: 0.97 - ETA: 0s - loss: 0.0752 - accuracy: 0.97 - ETA: 0s - loss: 0.0756 - accuracy: 0.97 - ETA: 0s - loss: 0.0754 - accuracy: 0.97 - ETA: 0s - loss: 0.0751 - accuracy: 0.97 - 4s 41ms/step - loss: 0.0748 - accuracy: 0.9729 - val_loss: 0.0993 - val_accuracy: 0.9550\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.96 - ETA: 2s - loss: 0.0861 - accuracy: 0.95 - ETA: 2s - loss: 0.0768 - accuracy: 0.96 - ETA: 3s - loss: 0.0862 - accuracy: 0.96 - ETA: 3s - loss: 0.0733 - accuracy: 0.96 - ETA: 3s - loss: 0.0802 - accuracy: 0.96 - ETA: 3s - loss: 0.0763 - accuracy: 0.96 - ETA: 3s - loss: 0.0894 - accuracy: 0.96 - ETA: 3s - loss: 0.0868 - accuracy: 0.96 - ETA: 3s - loss: 0.0841 - accuracy: 0.96 - ETA: 3s - loss: 0.0803 - accuracy: 0.97 - ETA: 3s - loss: 0.0805 - accuracy: 0.96 - ETA: 3s - loss: 0.0892 - accuracy: 0.96 - ETA: 3s - loss: 0.0830 - accuracy: 0.96 - ETA: 3s - loss: 0.0807 - accuracy: 0.96 - ETA: 2s - loss: 0.0779 - accuracy: 0.96 - ETA: 2s - loss: 0.0757 - accuracy: 0.96 - ETA: 2s - loss: 0.0752 - accuracy: 0.96 - ETA: 2s - loss: 0.0738 - accuracy: 0.96 - ETA: 2s - loss: 0.0729 - accuracy: 0.96 - ETA: 2s - loss: 0.0746 - accuracy: 0.97 - ETA: 2s - loss: 0.0735 - accuracy: 0.97 - ETA: 2s - loss: 0.0757 - accuracy: 0.97 - ETA: 2s - loss: 0.0740 - accuracy: 0.97 - ETA: 2s - loss: 0.0728 - accuracy: 0.97 - ETA: 2s - loss: 0.0716 - accuracy: 0.97 - ETA: 2s - loss: 0.0708 - accuracy: 0.97 - ETA: 2s - loss: 0.0762 - accuracy: 0.97 - ETA: 2s - loss: 0.0757 - accuracy: 0.97 - ETA: 2s - loss: 0.0743 - accuracy: 0.97 - ETA: 2s - loss: 0.0734 - accuracy: 0.97 - ETA: 1s - loss: 0.0739 - accuracy: 0.97 - ETA: 1s - loss: 0.0734 - accuracy: 0.97 - ETA: 1s - loss: 0.0725 - accuracy: 0.97 - ETA: 1s - loss: 0.0729 - accuracy: 0.97 - ETA: 1s - loss: 0.0731 - accuracy: 0.97 - ETA: 1s - loss: 0.0723 - accuracy: 0.97 - ETA: 1s - loss: 0.0725 - accuracy: 0.97 - ETA: 1s - loss: 0.0730 - accuracy: 0.97 - ETA: 1s - loss: 0.0727 - accuracy: 0.97 - ETA: 1s - loss: 0.0720 - accuracy: 0.97 - ETA: 1s - loss: 0.0724 - accuracy: 0.97 - ETA: 1s - loss: 0.0716 - accuracy: 0.97 - ETA: 1s - loss: 0.0710 - accuracy: 0.97 - ETA: 1s - loss: 0.0705 - accuracy: 0.97 - ETA: 1s - loss: 0.0701 - accuracy: 0.97 - ETA: 0s - loss: 0.0699 - accuracy: 0.97 - ETA: 0s - loss: 0.0701 - accuracy: 0.97 - ETA: 0s - loss: 0.0697 - accuracy: 0.97 - ETA: 0s - loss: 0.0697 - accuracy: 0.97 - ETA: 0s - loss: 0.0696 - accuracy: 0.97 - ETA: 0s - loss: 0.0696 - accuracy: 0.97 - ETA: 0s - loss: 0.0690 - accuracy: 0.97 - ETA: 0s - loss: 0.0690 - accuracy: 0.97 - ETA: 0s - loss: 0.0694 - accuracy: 0.97 - ETA: 0s - loss: 0.0698 - accuracy: 0.97 - ETA: 0s - loss: 0.0703 - accuracy: 0.97 - ETA: 0s - loss: 0.0701 - accuracy: 0.97 - ETA: 0s - loss: 0.0698 - accuracy: 0.97 - ETA: 0s - loss: 0.0696 - accuracy: 0.97 - ETA: 0s - loss: 0.0692 - accuracy: 0.97 - ETA: 0s - loss: 0.0690 - accuracy: 0.97 - ETA: 0s - loss: 0.0689 - accuracy: 0.97 - ETA: 0s - loss: 0.0697 - accuracy: 0.97 - ETA: 0s - loss: 0.0694 - accuracy: 0.97 - ETA: 0s - loss: 0.0692 - accuracy: 0.97 - ETA: 0s - loss: 0.0693 - accuracy: 0.97 - 5s 47ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.0871 - val_accuracy: 0.9672\n",
      "Epoch 29/30\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.00 - ETA: 2s - loss: 0.0397 - accuracy: 0.98 - ETA: 3s - loss: 0.0377 - accuracy: 0.98 - ETA: 3s - loss: 0.0340 - accuracy: 0.98 - ETA: 3s - loss: 0.0322 - accuracy: 0.99 - ETA: 3s - loss: 0.0404 - accuracy: 0.98 - ETA: 3s - loss: 0.0387 - accuracy: 0.98 - ETA: 3s - loss: 0.0352 - accuracy: 0.98 - ETA: 3s - loss: 0.0390 - accuracy: 0.98 - ETA: 3s - loss: 0.0389 - accuracy: 0.98 - ETA: 3s - loss: 0.0385 - accuracy: 0.98 - ETA: 3s - loss: 0.0458 - accuracy: 0.98 - ETA: 3s - loss: 0.0485 - accuracy: 0.98 - ETA: 3s - loss: 0.0469 - accuracy: 0.98 - ETA: 3s - loss: 0.0489 - accuracy: 0.98 - ETA: 3s - loss: 0.0491 - accuracy: 0.98 - ETA: 3s - loss: 0.0490 - accuracy: 0.98 - ETA: 3s - loss: 0.0510 - accuracy: 0.98 - ETA: 3s - loss: 0.0518 - accuracy: 0.98 - ETA: 3s - loss: 0.0508 - accuracy: 0.98 - ETA: 3s - loss: 0.0499 - accuracy: 0.98 - ETA: 3s - loss: 0.0513 - accuracy: 0.98 - ETA: 3s - loss: 0.0507 - accuracy: 0.98 - ETA: 3s - loss: 0.0516 - accuracy: 0.98 - ETA: 3s - loss: 0.0511 - accuracy: 0.98 - ETA: 3s - loss: 0.0507 - accuracy: 0.98 - ETA: 3s - loss: 0.0500 - accuracy: 0.98 - ETA: 3s - loss: 0.0489 - accuracy: 0.98 - ETA: 3s - loss: 0.0489 - accuracy: 0.98 - ETA: 3s - loss: 0.0490 - accuracy: 0.98 - ETA: 3s - loss: 0.0506 - accuracy: 0.98 - ETA: 3s - loss: 0.0508 - accuracy: 0.98 - ETA: 3s - loss: 0.0508 - accuracy: 0.98 - ETA: 3s - loss: 0.0505 - accuracy: 0.98 - ETA: 3s - loss: 0.0513 - accuracy: 0.98 - ETA: 3s - loss: 0.0502 - accuracy: 0.98 - ETA: 3s - loss: 0.0519 - accuracy: 0.98 - ETA: 3s - loss: 0.0520 - accuracy: 0.98 - ETA: 3s - loss: 0.0531 - accuracy: 0.98 - ETA: 3s - loss: 0.0522 - accuracy: 0.98 - ETA: 2s - loss: 0.0521 - accuracy: 0.98 - ETA: 2s - loss: 0.0543 - accuracy: 0.98 - ETA: 2s - loss: 0.0543 - accuracy: 0.98 - ETA: 2s - loss: 0.0540 - accuracy: 0.98 - ETA: 2s - loss: 0.0536 - accuracy: 0.98 - ETA: 2s - loss: 0.0556 - accuracy: 0.98 - ETA: 2s - loss: 0.0562 - accuracy: 0.98 - ETA: 2s - loss: 0.0568 - accuracy: 0.98 - ETA: 2s - loss: 0.0563 - accuracy: 0.98 - ETA: 2s - loss: 0.0565 - accuracy: 0.98 - ETA: 2s - loss: 0.0564 - accuracy: 0.98 - ETA: 2s - loss: 0.0562 - accuracy: 0.98 - ETA: 2s - loss: 0.0571 - accuracy: 0.98 - ETA: 1s - loss: 0.0564 - accuracy: 0.98 - ETA: 1s - loss: 0.0569 - accuracy: 0.98 - ETA: 1s - loss: 0.0574 - accuracy: 0.98 - ETA: 1s - loss: 0.0574 - accuracy: 0.98 - ETA: 1s - loss: 0.0576 - accuracy: 0.98 - ETA: 1s - loss: 0.0583 - accuracy: 0.98 - ETA: 1s - loss: 0.0586 - accuracy: 0.97 - ETA: 1s - loss: 0.0590 - accuracy: 0.97 - ETA: 1s - loss: 0.0591 - accuracy: 0.97 - ETA: 1s - loss: 0.0610 - accuracy: 0.97 - ETA: 0s - loss: 0.0606 - accuracy: 0.97 - ETA: 0s - loss: 0.0606 - accuracy: 0.97 - ETA: 0s - loss: 0.0605 - accuracy: 0.97 - ETA: 0s - loss: 0.0613 - accuracy: 0.97 - ETA: 0s - loss: 0.0612 - accuracy: 0.97 - ETA: 0s - loss: 0.0618 - accuracy: 0.97 - ETA: 0s - loss: 0.0621 - accuracy: 0.97 - ETA: 0s - loss: 0.0619 - accuracy: 0.97 - ETA: 0s - loss: 0.0619 - accuracy: 0.97 - ETA: 0s - loss: 0.0612 - accuracy: 0.97 - ETA: 0s - loss: 0.0619 - accuracy: 0.97 - ETA: 0s - loss: 0.0616 - accuracy: 0.97 - 5s 51ms/step - loss: 0.0616 - accuracy: 0.9781 - val_loss: 0.0929 - val_accuracy: 0.9599\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 1.00 - ETA: 2s - loss: 0.0548 - accuracy: 1.00 - ETA: 2s - loss: 0.0539 - accuracy: 0.99 - ETA: 3s - loss: 0.0493 - accuracy: 0.99 - ETA: 3s - loss: 0.0520 - accuracy: 0.99 - ETA: 3s - loss: 0.0478 - accuracy: 0.99 - ETA: 3s - loss: 0.0605 - accuracy: 0.98 - ETA: 3s - loss: 0.0563 - accuracy: 0.98 - ETA: 3s - loss: 0.0558 - accuracy: 0.98 - ETA: 3s - loss: 0.0612 - accuracy: 0.98 - ETA: 3s - loss: 0.0642 - accuracy: 0.97 - ETA: 3s - loss: 0.0604 - accuracy: 0.98 - ETA: 3s - loss: 0.0590 - accuracy: 0.98 - ETA: 3s - loss: 0.0605 - accuracy: 0.97 - ETA: 3s - loss: 0.0584 - accuracy: 0.97 - ETA: 3s - loss: 0.0607 - accuracy: 0.97 - ETA: 3s - loss: 0.0599 - accuracy: 0.97 - ETA: 2s - loss: 0.0585 - accuracy: 0.97 - ETA: 2s - loss: 0.0587 - accuracy: 0.97 - ETA: 2s - loss: 0.0602 - accuracy: 0.97 - ETA: 2s - loss: 0.0609 - accuracy: 0.97 - ETA: 2s - loss: 0.0623 - accuracy: 0.97 - ETA: 2s - loss: 0.0618 - accuracy: 0.97 - ETA: 2s - loss: 0.0601 - accuracy: 0.97 - ETA: 2s - loss: 0.0601 - accuracy: 0.97 - ETA: 2s - loss: 0.0612 - accuracy: 0.97 - ETA: 2s - loss: 0.0625 - accuracy: 0.97 - ETA: 2s - loss: 0.0611 - accuracy: 0.97 - ETA: 2s - loss: 0.0611 - accuracy: 0.97 - ETA: 2s - loss: 0.0605 - accuracy: 0.97 - ETA: 2s - loss: 0.0587 - accuracy: 0.98 - ETA: 1s - loss: 0.0578 - accuracy: 0.98 - ETA: 1s - loss: 0.0579 - accuracy: 0.98 - ETA: 1s - loss: 0.0576 - accuracy: 0.98 - ETA: 1s - loss: 0.0566 - accuracy: 0.98 - ETA: 1s - loss: 0.0561 - accuracy: 0.98 - ETA: 1s - loss: 0.0556 - accuracy: 0.98 - ETA: 1s - loss: 0.0554 - accuracy: 0.98 - ETA: 1s - loss: 0.0547 - accuracy: 0.98 - ETA: 1s - loss: 0.0539 - accuracy: 0.98 - ETA: 1s - loss: 0.0558 - accuracy: 0.98 - ETA: 1s - loss: 0.0561 - accuracy: 0.98 - ETA: 1s - loss: 0.0555 - accuracy: 0.98 - ETA: 1s - loss: 0.0562 - accuracy: 0.98 - ETA: 1s - loss: 0.0561 - accuracy: 0.98 - ETA: 0s - loss: 0.0569 - accuracy: 0.98 - ETA: 0s - loss: 0.0576 - accuracy: 0.98 - ETA: 0s - loss: 0.0573 - accuracy: 0.98 - ETA: 0s - loss: 0.0572 - accuracy: 0.98 - ETA: 0s - loss: 0.0565 - accuracy: 0.98 - ETA: 0s - loss: 0.0579 - accuracy: 0.98 - ETA: 0s - loss: 0.0583 - accuracy: 0.98 - ETA: 0s - loss: 0.0584 - accuracy: 0.98 - ETA: 0s - loss: 0.0602 - accuracy: 0.97 - ETA: 0s - loss: 0.0592 - accuracy: 0.97 - ETA: 0s - loss: 0.0590 - accuracy: 0.97 - ETA: 0s - loss: 0.0595 - accuracy: 0.97 - ETA: 0s - loss: 0.0597 - accuracy: 0.97 - ETA: 0s - loss: 0.0600 - accuracy: 0.97 - ETA: 0s - loss: 0.0600 - accuracy: 0.97 - 4s 42ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.0851 - val_accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix:\n",
      "[[590   0   0]\n",
      " [  1 541  48]\n",
      " [  0  30 550]]\n",
      "\n",
      "precision_recall:\n",
      "(array([0.99830795, 0.9474606 , 0.91973244]), array([1.        , 0.91694915, 0.94827586]), array([0.99915326, 0.93195521, 0.93378608]), array([590, 590, 580], dtype=int64))\n",
      "\n",
      "accuracy_score:\n",
      "0.9551136363636363\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-753ec8f8cbbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\naccuracy_score:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_test = to_categorical(y_test, num_classes=3)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_pred,y_test)\n",
    "print(\"confusion Matrix:\")\n",
    "print(cm)\n",
    "cma =  precision_recall_fscore_support(y_pred,y_test)\n",
    "print(\"\\nprecision_recall:\")\n",
    "print(cma)\n",
    "\n",
    "cma =  accuracy_score(y_pred,y_test)\n",
    "print(\"\\naccuracy_score:\")\n",
    "print(cma)\n",
    "c=(y_test==1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "Graph_ploat"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEICAYAAABBBrPDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA76UlEQVR4nO3deXiU9bnw8e+dyR6SkAUQCJAgIpssEnBXXFBQERX3Wqutou+p1tMePS6ni9ba+kpt7VGroi9SrUrBDVRU1KJU60JQkH0xLAkBsu97cr9/PE/CELJMlmFIcn+ua66ZZ53fk4G557fdj6gqxhhjTEuCAl0AY4wxRzcLFMYYY1plgcIYY0yrLFAYY4xplQUKY4wxrbJAYYwxplUWKIzp5URkmohkBroc5uhlgcL0GCLyiYgUiEhYoMtiTE9igcL0CCKSDJwBKHDJEX7v4CP5fsYcaRYoTE9xA/AlsBD4kfcGERkiIm+ISI6I5InIk17bbhGRzSJSIiKbROREd72KyAiv/RaKyO/c19NEJFNE7hGR/cALIhInIu+471Hgvk7yOj5eRF4QkSx3+1vu+g0iMstrvxARyRWRic1dpIhcLCJrRaRQRP4tIuPd9feKyGtN9v2LiPyv+/omr+tMF5FbO/A3Nr2UBQrTU9wAvOw+LhCRAQAi4gHeAXYDycBgYJG77UrgAffYGJyaSJ6P73cMEA8MA+bi/F96wV0eClQAT3rt/xIQCYwF+gN/dte/CFzvtd+FwD5VXdv0Dd0gtgC4FUgAngWWuU1trwIXikiM13VfBbziHp4NXOxe503AnxuCojFtUlV72KNbP4DTgRog0V3eAvzcfX0KkAMEN3PcB8CdLZxTgRFeywuB37mvpwHVQHgrZZoIFLivBwL1QFwz+w0CSoAYd/k14L9bOOfTwENN1m0FznJffwbc4L6eDnzfSvnearh293oyA/052uPofViNwvQEPwJWqGquu/wKB5ufhgC7VbW2meOGAN938D1zVLWyYUFEIkXkWRHZLSLFwCqgr/vLfgiQr6oFTU+iqlnA58AcEekLzMSpFTVnGPBfbrNToYgUuuce5G5/BbjWfX0dB2sTiMhMEflSRPLd4y4EEjt47aaXsU44062JSAROE4vH7S8ACMP5kp4AZABDRSS4mWCRARzbwqnLcZqKGhwDeA8hbZp2+b+A44GTVHW/28fwLSDu+8SLSF9VLWzmvf4G3Izz//ELVd3bQpkygIdV9eEWti8BHnP7Ri7DqU3hNk29jtPEtlRVa9w+EmnhPMYcwmoUpru7FKgDxuA090wERgP/wvli/BrYBzwiIlEiEi4ip7nHPg/cJSKTxTFCRIa529YC14mIR0RmAGe1UY5onH6JQhGJB37TsEFV9wHvAX91O71DRORMr2PfAk4E7sTps2jJc8BtInKSW94oEblIRKLd98kBPsHpK9mpqpvd40JxgmcOUCsiM4Hz27geYxpZoDDd3Y+AF1R1j6rub3jgdCT/AOdX8yxgBLAHp1ZwNYCqLgEexmmiKcH5wo53z3une1yhe5632ijH40AEkIsz+ur9Jtt/iNOPsgWnY/k/GzaoagXOL/4U4I2W3kBV04Bb3GsrAHYANzbZ7RXgPLyanVS1BPgZsNg97jpgWRvXY0wjUbUbFxkTaCLya2Ckql7f5s7GHGHWR2FMgLlNVT/BqXUYc9SxpidjAkhEbsHppH5PVVcFujzGNMeanowxxrTKahTGGGNa1aP6KBITEzU5OTnQxTDGmG5jzZo1uarar7V9elSgSE5OJi0tLdDFMMaYbkNEdre1jzU9GWOMaZUFCmOMMa2yQGGMMaZVFiiMMca0ygKFMcaYVlmgMMYY0yoLFMYYY1plgcIYY7opVeWz7bk882lHb9Tomx414c4YYwIhr7SK8uo6n/aNjQwhJjyk0+/5VXoej324ja935pMUF8GNpyYTHuLp9HmbY4HCGGPaqbaunm/2FLJyazYrt2SzZX+Jz8eGeIRzRw3gytQkzhrZj2BP+xp21uwu4M8fbuOzHbn0jw7jwUvGcs3UIYQF+ydIgAUKY4zxSX5ZNZ9uy+afW3JYtS2HoooagoOE1OQ47pkxisQ+oT6dZ8v+Et76di/vb9xPv+gwLj9xMFdOHsKI/n1aPW59ZhGPfbiVT7bmkBAVyi8vGs31Jw/zWy3CW49KM56amqqW68mY7q+ypo5v9xTybUYBoZ4gBsSEu48wBsSEH5Evx9q6erbsL2HllmxWbs3m24xCVCGxTyhnjezPOaP6c8bIxA41I1XX1rNyazZL0jJYuTWHunrlxKF9uTJ1CBePH0i01zk37yvmTx9u48NNBzgmoo47UyO5bLgSXrEPijKdh9bDZc906DpFZI2qpra6jwUKY0ygVdbU8c2eAr5Mz+fL9DzWZhRSXVvf4v6xESGNQaN/tBNA4qNCCQvxEOYJIiwkiNDGZ88hy8FBQRRX1pBXWk1uaRV5pVXkNr6upqiklJiydAZW7SSKCrbXJ+EZOJYpo4/lnFH9OWFwLEFB0mXXnl1SyVvf7mVJWibbs0sJDwniorEDuDHqc/J2rKE6fw9JnnxSgvOJqC1qcrRA9EBIHAE/ertD72+BwhhzVKqobggMeXyVnu8Ehrp6ggTGDorl5OHxnDw8gdTkeFDYX1zJAfeRXVLFgeJK8gsLicnfwNDSdYyu2Uh/Ctin8WRpAlmayF73OUsTOEActU1a2oV6kiSHUZLB+JC9jAvJZITuYVDdXjw0E6SiB0L/0dB/DAwY6zz3Ox5CIrrkb6KqrM0oZElaBuPXPcQ1soJSjaAiahB9j0khJH4oxAyG2CEQm+Q8YgaBp3Md474ECuujMKYnUQXpul+7nXlvVSW3tJqduWXsyi1jZ14ZO3PK2JVXxvc5pdTUKUECJwyO5abTkjlpeDypyfHNNuXERoZwfHQV1K2DvC8g+0vYtxbqa533GjCa2ujjGVGyj6CSb/BUFhxaNAmiKrw/FZEDqQjrR1TlfvoU78BTW35wpz7DYMAJ0P9qGDAG+o+FsGjI2QwHNkH2JjiwEb5+DuqqnGMkCOKPdQLHGb+AgRM6/OcTESYN6cukrX8GWUHG6JuJuuj39OsT1uFzdhWrURjTXdTVQElDu/ReKMo42Ebd8KivhaRUGHoKDD0ZkqZA2KGdpGVVtXy2I5cQjzCobwSD+ka0r51d1Xnv7M3U7ttAVdZ6OLCJ8OJ0ikIHsjVsHF/XHseK0hQ2VvUDnOAR4hGGxkeSkhjFiP7RTmAYFndIe3yj6jLI2eJ8MWd8BXu+hLwdzjZPKAye7FzfkJNhyFSIjD/8eO+/UfFe92+UAcX7IPqYg7WCAWOh36jD/k4tfw61kJ8O2RsPBpA9X0BNJVy5EEae7/vfsqlP58HK30Hqj+GiPx2RoG9NT8YcrapKnS++yiKoKoaqEqgsdl43rGtcLnYCRMk+p9PSW0Q8xHo1R6g6X6wHNjj7igeOGUdd0slsDB7DP7IH88a2OipqDh3zHx0W7AaNcAb1jSApJpihUTUMDq8huiaP6qz1BGVvIrJoK4nl6UTUlzUem6mJbKtPIl0HMkyymerZRizOcNGKkDhKB0wheNgpRB9/OsGDJkKw1+ig5r50D2yEgl2A+90UEecEhKHuY+BECAnv8o+kU0r2w8tXOmW/6DFIvan95/jir/DBfTD+Grj0aQg6MvOhLVAYc7Qo2e/8Kt7zpfPrc/960BYmaAVHQHgMhMUcfI4eeLBdOjbJDQyDITSq+XNUFlOfsZq961dSlf45g0s3EoHTXJIfOpC6wVOR4DBqygqpqyhCqorx1JQQVltKhJYTTvVhpyzSSLYxlL2hKeRHHUdF3PHIgDEkJvZjcN8IBsaGkxQXSWgQkLfduc49XznPBTsPXltSqnM9OZshZ1szzThjnF/6Db/241KO2Jdmp1SVwpIbYceHcMZ/wTm/8r1GsGYhvH0njJ4FVywEz5HrFbBAYUwg1Nd7fVG6gaFgl7Ot4Yty6MlwzHiI6OsVEGKd5050TqoqG7OKWbp2L2+v28f+4koiQz3MGJ3AdUOLmMQWPJlfQWYaoIcGI6/nmuBoCjWC/NpwSoP7Epk0nv6DkonvE4Z0pDmkIVBmuIGjNNtp7vEOCl3YMRwwdbXw7i/gm7/BCVfB7KcOrUE157sl8MYtMOI8uOaVtvfvYhYojPGXQ/oLMg+2hRfugb1roMLtTI1MdJtMTnEex5wAwaEUllezr6iSY/v1ITS4c7+WiypqSNvlDCv9eEs26TllhHiEs0b2Z/bEQZw3egARof6fd2BcqvCvx+CfD0HyGXD1350fBM3Z8i7844fOv43rXwtIoAz4qCcRmQH8BfAAz6vqI022xwELgGOBSuDHqrrB3bYLKAHqgNq2LsSYLqPqfNEf0lHcpOO4dH8L/QVJMOqig4Ehfnhj88PuvDI+/CKTDzcdIG13AXX1SqgniNEDozkhKZbxSX0ZnxTLiH59Wk3rUFRew9duYPhqZx4bs4pRhVBPEKnJccw9Yzgzxh1D38gj+8vUuETgzLug71B46z9gwQXwg9eg75BD99vxsdNUNWgSXLfoqK5N+a1GISIeYBswHcgEVgPXquomr33mAaWq+qCIjAKeUtVz3W27gFRVzfX1Pa1GYXxWV+v88s//vvlAUFN+6P6e0Cb9A0numPaW+wvq65V1mYV8tPkAH246wLYDpQAcPyCa88b0Z+SAaDZlFfNdZhEb9hZRUuUM9YwI8TB2UIwbPGIZMzCW3XlljZPRNu93A0NwECcO7ctJKQmcPDyBSUP7HpEZy6Yddq6CRdc7QeAHiw8On939b3jpckgYATe+7XTYB0hAm55E5BTgAVW9wF2+D0BV/+C1z7vAH1T1M3f5e+BUVT1ggcJ0ubJc2P4hbF8B33/sjC5qENXf/dJvMqGpIRBEJvrUoVpZU8e/v8/lw00H+GhzNjklVXiChCnJcUwfcwzTRw9gaELkYcfV1ys788pYn1nEusxC1mcWsSGriMqag7WWsOAgJg+LcwNDPBOGWGDoFrI3w9+vgMpCuPJvzlDev13iDNG96T3o0y+gxQt009NgIMNrORM4qck+64DLgc9EZCowDEgCDuCMjVshIgo8q6rzm3sTEZkLzAUYOnRol16A6ebq62H/Oti2wgkOe9cA6gSFUbPguPOcDuWYwZ0ebrk+s4hXV+9h2dosSqtqiQr1MO34/pw3pj9nH9+/zWagoCDh2H59OLZfHy6dNBhwcg3tyCll875ikuIiGZ8U69cMocZP+o+Gmz+CV65yHqF9IDIOblga8CDhK38GiuaGRjStvjwC/EVE1gLrgW+BWnfbaaqaJSL9gQ9FZIuqrjrshE4AmQ9OjaKrCm+OgIoCyEvv+vMWZzqBYfuHUHoAEBh8Iky7D46b7ozD74LhlsWVNSxdm8Wir/ewMauYsOAgLho/kEsmDOKUYxM6/aUe7Ali1DExjDomptNlNQEWMxBuWg6v/cSZK3LDMqf22k34M1BkAt69N0lAlvcOqloM3AQgzpi7ne4DVc1yn7NF5E1gKnBYoDDdhKozIqhhuGjGV85/GH8Ji4UR58BxFzjDDrvol5uq8s2eAl79OoN3v9tHRU0dowfG8NvZY5k9cTCxEZ2/IY3pocKinX6K+joI6l41Q38GitXAcSKSAuwFrgGu895BRPoC5apaDdwMrFLVYhGJAoJUtcR9fT7wWz+W1XS1+jpndnBDYNjzFZS4vxPCYpy0C2MvdyZUBXXxP8PwWKcG0clkad4Kyqp549u9LPp6D9uzS4kK9XDppEFcM2Uo45NiOza3wPRO3SxIgB8DharWisjtwAc4w2MXqOpGEbnN3f4MMBp4UUTqgE3AT9zDBwBvuv/5goFXVPV9f5XVdJHKYmdc+MY3YPcXUO3e9StmMAw79WAKhv5jjsr/LDV19ewrrGRPfjkZBeXsyXcemfnlbN5XQnVdPROG9OWRy09g1oRBRIVZTk3TO9iEO9M5NZVOyoL1S2DbB1Bb6YwfHzH9YGK6puPH2ym7uJL3N+4nOCiIlMQoUhKjGBDTsRnCFdV17MorY2eu88hwg0FGQTlZhZXU1R/8/xAcJCTFRTAkPpLjB0QzZ3ISowdaf4HpWQI96sn0VPV1zvjw9a/B5mVO4rqofnDiDXDClU7G0k42xVTX1vPPLQdYkpbJJ9tyDvkCB2euQXJiFCmJkSQnRDUGkOTEKKLDg8nIL2dnbjk7c0vZmVvupLnOLWN/ceUh50nsE8aQ+AhOHBrHpRMjGRIXyZD4SIYmRHJMTDieLrxBjTHdlQWKnkjVGe1TWeRmIC06NBOp93NVidOW3zTfUHM5gMpyYcNrsOENKMuG0GgnidkJV0DKWV2SyGxTVjFL1mSwdG0W+WXVDIgJY+6Zw5lzYhLhIUHs8v7yzytj874SVmw8QG19yzXjuMgQUhKjOHVEAikJUaT0iyI5wQkqfaz5yJg22f+SnqSyCNYtgrQFTi7/FolXAIiGuuqDgaO2spXjAE+Yk2//hCvhuPO7JO1AYXk1S9dmsWRNBhv2FhPiEaaPGcCVk4dwxnGJh6SzSIqL5PTjEg85vqaunr0FFY3NScWVNQxLiCQlsQ8pCVHERtpIJGM6wwJFT5D1rRMc1r/mpJ4YdCJc8Afo098ZAeRdKwiLdib8tDSPoLb60HsieN8nwRPqzEMIj+1UcVWVzIIK0nbn89HmbD7ceIDqunrGDIzhgVljmD1xMHFRvucpCvEEkew2O53dqZIZY5pjgaK7qi6HDa87ASLrGwiJdJqAUn/sJBnrqOBQCE6EqMS29/VRXb2yZX8xabsKWL0rn7RdBY19BXGRIVx30lCuTE1i7KDOBSBjjH9YoOhucrZC2guw7hXnV3+/UTBzHky4utO/9LtKRXUdazMKSduVz+rdBXyzu4BSN+HdwNhwpqTEMyU5jtRh8Rx/TLR1GBtzlLNAcbSrKITM1c6ktZ3/gsyvISgExsx2ag/DTj0i99X1RU5JFc9/ls7fv9hNWXUdIk6m1EsnDWJKcjypyfEM7nv0plI2xjTPAsXRpjDDazbzl26aC3VmLx8zHs79DUz64VGVTCyrsIL5q9J59es91NTVc/H4QVw6aRCTh8ZbR7IxPYAFikCrKHQmqzUEhuK9zvrQaDfNxaXOpLXBk1u+P3KA7Mot4+lPvueNbzNRhctPHMz/mTaClMSjq5zGmM6xQBFIxfvgpcucm8xHD/K6ZebJbg6koy/NBcC2AyU8tXIHb6/LItgTxLVThzL3zOEkxR1+nwVjTPdngSJQ8nfCi7OhPA9++CYMP/uo6WtoyfrMIp5cuZ0PNh4gMtTDzWcM5+bTU+gf07l7ORhjjm4WKALhwCanJlFX5eSlT5oc6BI1qqypIyO/nPTcssa0Fw2P7JIqYsKD+dm5x3HTqcntmutgjOm+LFAcaZlp8Pc5EBzu3Aax/+iAFaWmrp6la7P4LrOwMRjsLazAO09kQlQoyYlRnDmyH2MHxXDF5CSiw62D2pjexALFkZT+Cbx6nTNi6YdvQXxKwIry+Y5cHnx7I9sOlBIdHszwxCgmD4tjzolJDPfKhWQ34jHGWKA4Uja/A6/dBAkjnD6J6GMCUoyM/HIefncz72/cz5D4COb/cDLTxwywG+8YY1pkgeJIWPsqLP2pk1rjB0sgMv6IF6Giuo6nP9nBs6vSCRLh7guO5yenpxAecnSOrDLGHD38GihEZAbwF5w73D2vqo802R4HLACOBSqBH6vqBl+O7Ta+ehbe+28nDfc1r0BYnyP69qrKu+v38ft3N5NVVMklEwZx34WjGBhrM6SNMb7xW6AQEQ/wFDAdyARWi8gyVd3ktdv9wFpVvUxERrn7n+vjsUc3Vfj0Ufjk9zDqYrhiAQSHHdEibN5XzAPLNvLVznzGDIzh8WsmMTXlyNdmjDHdmz9rFFOBHaqaDiAii4DZOPfGbjAG+AOAqm4RkWQRGQAM9+HYo9uHv4J/PwETroNLnuiSm/r4QlXZlVfOgs928vJXu4mNCOHhy8ZxzZShlnzPGNMh/vz2GgxkeC1nAic12WcdcDnwmYhMBYYBST4eC4CIzAXmAgwdOrRLCt5p3y1xgsSUW2Dmoy3f+6GLlFTW8O/v81i1LYdV23PIyK/AEyTccEoyPz9vpOVbMsZ0ij8DRXM/X5ver/IR4C8ishZYD3wL1Pp4rLNSdT4wHyA1NbXl+2EeKQW74d1fwJCTYMYjfgkS9fXKhqwiJzBsy+WbPQXU1itRoR5OOTaRuWcMZ9rx/RkSbyk1jDGd589AkQkM8VpOArK8d1DVYuAmAHHGZ+50H5FtHXtUqquFN+Y6ry+f36XNTarKBxv3s3z9fj7bkUt+WTUA4wbHMPfM4Zw5sh8nDo0jNNi/tRdjTO/jz0CxGjhORFKAvcA1wHXeO4hIX6BcVauBm4FVqlosIm0ee1T612OQ8SVc/hzEJXfZaYsqarj/jfW8u34fiX1COWtkP84cmcjpI/rRL/rIdpAbY3ofvwUKVa0VkduBD3CGuC5Q1Y0icpu7/RlgNPCiiNThdFT/pLVj/VXWLpHxNXz6f+GEq2D8VV122jW7C/jZq99yoLiSe2aM4tYzhxNkndLGmCNIVAPfrN9VUlNTNS0t7ci/cWUxPHM6oHDbZ11yS9K6euWZT7/nTx9uY2BsOE9cO4lJQ+M6X1ZjjPEiImtUNbW1fWxmdldYfjcUZThJ/rogSGQXV/LzxWv5fEceF48fyO8vP4EYS8RnjAkQCxSdtf41+G4RnHWvc8OhTlq5NZu7Fq+jrLqW/zvnBK5KHWJ5mIwxAWWBojMK98A7v4CkqXDm3Z06VXVtPY++v4XnP9vJqGOi+cd1JzOif3QXFdQYYzrOAkVHNQyF1XqY81ynhsLuyi3jjle/Zf3eIm44ZRj3XzjakvUZY44aFig66rM/w54v4LL5HR4Kq6q8/s1efrN0A8GeIJ794WQuGBuY9OPGGNMSCxQdkbEaPvkDjLuiw0NhC8qq+Z+31rN8/X6mpsTz+NUTGdTXMroaY44+Fijaq7IY3rgZYgbDxX+CDnQ0r9qWw11L1lFQXs29M0dxyxnDLWGfMeaoZYGivd67x+nEvnF5u4fCVtbU8ch7W1j4712M6N+HBTdOYdzgzg+nNcYYf7JA0R7bPoB1r8CZ/w3DTmnXoRuzivjPRWvZnl3Kjacmc+/MUdZhbYzpFixQtMfOVRAcAWf9t8+H1NUrz/0rncdWbCUuMpS//XgqZ43s58dCGmNM17JA0R756RCfAh7fZklnFpTzi8Xr+HpnPjPGHsMfLj+BuKhQPxfSGGO6lgWK9shPh/hjfdr17XVZ3P/GeupVmXfFeK6YnGQzrI0x3ZIFCl/V10PBLhhxXpu7bsoq5s5F3zJxSF8ev3oSQxPsBkLGmO7LAoWvSvZBbSXED291N1XlgWUb6RsZygs3TrXbkBpjuj27HZqv8tOd5/iUVndbti6Lr3flc/cFx1uQMMb0CBYofFWw03lupUZRVlXL75dv5oTBsVyVOqTF/Ywxpjvxa6AQkRkislVEdojIvc1sjxWRt0VknYhsFJGbvLbtEpH1IrJWRAJwN6Im8tMhKARiklrc5Yl/7uBAcRUPzh5rM62NMT2G3/ooRMQDPAVMBzKB1SKyTFU3ee32U2CTqs4SkX7AVhF52b2HNsDZqprrrzK2S3469B3aYpbY9JxS/t9n6cw5MYkT7U50xpgexJ81iqnADlVNd7/4FwGzm+yjQLQ440b7APlArR/L1HH5O1tsdlJVfvvOJsKCPdwz8/gjXDBjjPEvfwaKwUCG13Kmu87bk8BoIAtYD9ypqvXuNgVWiMgaEZnrx3K2TbXVQPHx5mw+2ZrDf553HP2jw49w4Ywxxr/8GSiaa6TXJssXAGuBQcBE4EkRiXG3naaqJwIzgZ+KyJnNvonIXBFJE5G0nJycLin4Ycpyobqk2RFPlTV1/PadTYzo34cfnZrsn/c3xpgA8megyAS8h/4k4dQcvN0EvKGOHcBOYBSAqma5z9nAmzhNWYdR1fmqmqqqqf36+SmHUisjnp7/Vzp78st5YNZYQjw2iMwY0/P485ttNXCciKSISChwDbCsyT57gHMBRGQAcDyQLiJRIhLtro8Czgc2+LGsrWucQ3FooMgqrOCpld8zY+wxnH5cYgAKZowx/ue3UU+qWisitwMfAB5ggapuFJHb3O3PAA8BC0VkPU5T1T2qmisiw4E33dxIwcArqvq+v8rapvx0p3h9hx6y+uHlm6lX5ZcXjw5MuYwx5gjwawoPVV0OLG+y7hmv11k4tYWmx6UDE/xZtnbJ3wmxQyA4rHHVv7/P5d3v9vHz80aSFGe5nIwxPZc1qvuiIb24q6aungeXbSIpLoJbz2o995MxxnR3Fih80SRQvPTFbrYeKOFXF4+xu9QZY3o8CxRtqSiEivzGjuzc0ir+/NE2zjgukfPHDAhs2Ywx5giwQNGWJkNjH31/CxXVdfxm1li7EZExplewQNGWhqGxcSl8l1nI4rRMfnx6CiP69wlsuYwx5gixQNGW/IYaRQr/3JINwB3njAhggYwx5siyQNGW/J3Q5xgIjSKvtJq4yBCiw+2GRMaY3sMCRVu8RjzllVWR0CesjQOMMaZnaTNQiMjFItJ7A0rBTq8RT9UkRIUGuEDGGHNk+RIArgG2i8ijItK7clVUl0HJPohzaxSlVSRajcIY08u0GShU9XpgEvA98IKIfOGm9o72e+kCrWCX89zY9FRNQh+rURhjehefmpRUtRh4HecudQOBy4BvROQOP5Yt8PIPzqGoqaunsLyGhCirURhjehdf+ihmicibwD+BEGCqqs7ESdp3l5/LF1iN6cVTKChzbuNtNQpjTG/jS/bYK4E/q+oq75WqWi4iP/ZPsY4S+ekQEQcRceQWFAOQaIHCGNPL+BIofgPsa1gQkQhggKruUtWP/Vayo4HXiKe8sioA68w2xvQ6vvRRLAHqvZbr3HU9X36614inhqYnCxTGmN7Fl0ARrKrVDQvu657f/lJbDUWZh2SNBeujMMb0Pr4EihwRuaRhQURmA7m+nFxEZojIVhHZISL3NrM9VkTeFpF1IrJRRG7y9Vi/K9wDWu/V9FRNqCeI6DC/3hTQGGOOOr58690GvCwiT+Lc1zoDuKGtg0TEAzwFTAcygdUiskxVN3nt9lNgk6rOEpF+wFYReRmneautY/3La8QTQG5JFQl9Qi21uDGm12kzUKjq98DJItIHEFUt8fHcU4Ed7v2vEZFFwGzA+8tegWhxvn37APlALXCSD8f6V2OgOFijsGYnY0xv5FM7iohcBIwFwht+Uavqb9s4bDBO7aNBJk4A8PYksAzIAqKBq1W1XkR8ObahbHOBuQBDhw715XJ8U7ATQvtAVD/ASd9hk+2MMb2RLxPungGuBu7AaXq6Ehjmw7mba6PRJssXAGuBQcBE4EkRifHxWGel6nxVTVXV1H79+vlQLB81jHhyA2NuqdUojDG9ky+d2aeq6g1Agao+CJwCDPHhuMwm+yXh1By83QS8oY4dwE5glI/H+pdXenFVJa/MEgIaY3onXwJFpftcLiKDgBogxYfjVgPHiUiKiITiZKFd1mSfPcC5ACIyADgeSPfxWP+pr4OC3Y39E+XVdVTW1FuKcWNMr+RLH8XbItIXmAd8g9ME9FxbB6lqrYjcDnwAeIAFqrpRRG5ztz8DPAQsFJH1OM1N96hqLkBzx7b34jqsKBPqaw5mjbXJdsaYXqzVQOHesOhjVS0EXheRd4BwVS3y5eSquhxY3mTdM16vs4DzfT32iGky4im3zCbbGWN6r1abnlS1HnjMa7nK1yDRrRUcTC8OB2sUiTbqyRjTC/nSR7FCROZIb5pplp8OnjCIHgQ4Q2PBahTGmN7Jlz6KXwBRQK2IVOL0Jaiqxvi1ZIGUvxPikiHIiaN57r0o4q0z2xjTC/kyM7vn3/K0qfyD6cXBSQgYHRZMeIgngIUyxpjAaDNQiMiZza1veiOjHkPV6aMYflbjqrzSahKjrX/CGNM7+dL0dLfX63CcHE5rgHP8UqJAKz0ANeWH1CjyyqpsDoUxptfypelplveyiAwBHvVbiQKtSdZYgNySapITIwNUIGOMCSxfRj01lQmM6+qCHDUaAkXcwUCRV1Zlk+2MMb2WL30UT3AwIV8QTvK+dX4sU2Dl7wTxQF8nE21dvZJfVk2iNT0ZY3opX/oo0rxe1wKvqurnfipP4OWnO0HCEwJAYXk19WrpO4wxvZcvgeI1oFJV68C5c52IRKpquX+LFiBeWWPh4BwKm2xnjOmtfOmj+BiI8FqOAD7yT3ECTLXZORSA3bTIGNNr+RIowlW1tGHBfd0zhwBVFEBV0aFDYxvyPFmNwhjTS/kSKMpE5MSGBRGZDFT4r0gB1NyIp8Y8T1ajMMb0Tr70UfwnsEREGu4wNxDn1qg9T/6hWWPB6aMIEugbERKgQhljTGD5MuFutYiMwrn7nABbVLXG7yULhMYaxcFbgueWVhMfFUZQUO9JnmuMMd7abHoSkZ8CUaq6QVXXA31E5D98ObmIzBCRrSKyQ0TubWb73SKy1n1sEJE6EYl3t+0SkfXutrTDz+4H+ekQMxhCDvbd55VWWf+EMaZX86WP4hb3DncAqGoBcEtbB4mIB3gKmAmMAa4VkTHe+6jqPFWdqKoTgfuAT1U132uXs93tqT6Us/MKDh3xBE7Tkw2NNcb0Zr4EiiDvmxa5AcCXb86pwA5VTVfVamARMLuV/a8FXvXhvP6Tn+7ch8JLXmmVDY01xvRqvgSKD4DFInKuiJyD82X+ng/HDQYyvJYz3XWHEZFIYAbwutdqxbm73hoRmdvSm4jIXBFJE5G0nJwcH4rVgqoSKMs5vEZRajUKY0zv5suop3uAucD/wenM/hZn5FNbmuv91WbWAcwCPm/S7HSaqmaJSH/gQxHZ0tw9MFR1PjAfIDU1taXzt62ZEU+VNXWUVNWSaENjjTG9WJs1ClWtB74E0oFU4Fxgsw/nzgSGeC0nAVkt7HsNTZqdVDXLfc4G3sRpyvKfZtKLN6TvsM5sY0xv1mKNQkRG4nyBXwvkAf8AUNWzfTz3auA4EUkB9rrnuq6Z94kFzgKu91oXBQSpaon7+nzgtz6+b8e0NtnO+iiMMb1Ya01PW4B/AbNUdQeAiPzc1xOraq2I3I7Tx+EBFqjqRhG5zd3+jLvrZcAKVS3zOnwA8Kbbhx4MvKKq7/v63h1SsBOi+kF4TOOqhvQd1kdhjOnNWgsUc3BqAStF5H2cUUvtmnWmqsuB5U3WPdNkeSGwsMm6dGBCe96r0/J3HlKbgIMJAa2PwhjTm7XYR6Gqb6rq1cAo4BPg58AAEXlaRM4/QuU7cvLTm51DAVajMMb0br50Zpep6suqejFOh/Ra4LBZ1t1aTQUU721maGwVESEeIkN9GRxmjDE9U7vuma2q+ar6rKqe468CBUTBbuc5/tCmJ5tDYYwx7QwUPVbj0NhDaxS5ZdWWXtwY0+tZoABnxBM02/SUGGU1CmNM72aBApwaRVgsRMQdstqanowxxgKFIz/d6Z84mPsQVSWvrMqanowxvZ4FCnDmUDRpdiqurKWmTkmwpidjTC9ngaK+DkoPNDPiySbbGWMM+JY9tmcL8sB9mVBbdcjqXEvfYYwxgNUoHEEeCI08ZJUlBDTGGIcFihbkWopxY4wBLFC0qKFGEW+d2caYXs4CRQvySquJiwwh2GN/ImNM72bfgi2wORTGGOOwQNGC3NJqm0NhjDH4OVCIyAwR2SoiO0TksNTkInK3iKx1HxtEpE5E4n051t/ySqtsDoUxxuDHQCEiHuApYCYwBrhWRMZ476Oq81R1oqpOBO4DPlXVfF+O9be8MsvzZIwx4N8axVRgh6qmq2o1zq1UZ7ey/7XAqx08tkvV1NVTWF5jcyiMMQb/BorBQIbXcqa77jAiEgnMAF7vwLFzRSRNRNJycnI6XWiAArsFqjHGNPJnoJBm1mkL+84CPlfV/PYeq6rzVTVVVVP79evXgWIeriF9h022M8YY/waKTGCI13ISkNXCvtdwsNmpvcd2ubwyN32HdWYbY4xfA8Vq4DgRSRGRUJxgsKzpTiISC5wFLG3vsf6S15AQ0IbHGmOM/7LHqmqtiNwOfAB4gAWqulFEbnO3P+PuehmwQlXL2jrWX2VtKrfUahTGGNPAr2nGVXU5sLzJumeaLC8EFvpy7JGSW1pNiEeICbcs7MYYYzOzm5FXWkVCVBgizfWpG2NM72KBohk22c4YYw6yQNGMvFJLCGiMMQ0sUDQjt7Ta5lAYY4zLAkUTqkpemSUENMaYBhYomiivrqOypt7mUBhjjMsCRRONk+2sRmGMMYAFisPkNqbvsBqFMcaABYrDNNQoEi3FuDHGABYoDpNXajUKY4zxZoGiiTz3XhTx1pltjDGABYrD5JZWER0WTHiIJ9BFMcaYo4IFiiZySy19hzHGeLNA0YSl7zDGmENZoGgir7TaJtsZY4wXCxRN5JVZjcIYY7z5NVCIyAwR2SoiO0Tk3hb2mSYia0Vko4h86rV+l4isd7el+bOcDerqlfwySwhojDHe/HYLNxHxAE8B04FMYLWILFPVTV779AX+CsxQ1T0i0r/Jac5W1Vx/lbGpwvJq6tXulW2MMd78WaOYCuxQ1XRVrQYWAbOb7HMd8Iaq7gFQ1Ww/lqdNDXMorOnJGGMO8megGAxkeC1nuuu8jQTiROQTEVkjIjd4bVNghbt+bktvIiJzRSRNRNJycnI6VeBcd1a2pRg3xpiD/Nb0BDR3w2lt5v0nA+cCEcAXIvKlqm4DTlPVLLc56kMR2aKqqw47oep8YD5Aampq0/O3S2OeJ+ujMMaYRv6sUWQCQ7yWk4CsZvZ5X1XL3L6IVcAEAFXNcp+zgTdxmrL86mCeJ6tRGGNMA38GitXAcSKSIiKhwDXAsib7LAXOEJFgEYkETgI2i0iUiEQDiEgUcD6wwY9lBZw+iiCBvhEh/n4rY4zpNvzW9KSqtSJyO/AB4AEWqOpGEbnN3f6Mqm4WkfeB74B64HlV3SAiw4E3RaShjK+o6vv+KmuD3NJq4qPCCApqrtXMGNOcmpoaMjMzqaysDHRRTCvCw8NJSkoiJKT9P4T92UeBqi4HljdZ90yT5XnAvCbr0nGboI6kvNIq658wpp0yMzOJjo4mOTkZ98edOcqoKnl5eWRmZpKSktLu421mtpfc0ipLCGhMO1VWVpKQkGBB4igmIiQkJHS41meBwkteWTUJdmc7Y9rNgsTRrzOfkQUKL3mWYtwYYw5jgcJVWVNHaVWtTbYzppspLCzkr3/9a4eOvfDCCyksLOzaAvVAFihcjek7LM+TMd1Ka4Girq6u1WOXL19O3759/VCqzlFV6uvrA12MRn4d9dSd2GQ7Yzrvwbc3simruEvPOWZQDL+ZNbbF7ffeey/ff/89EydOZPr06Vx00UU8+OCDDBw4kLVr17Jp0yYuvfRSMjIyqKys5M4772TuXCcrUHJyMmlpaZSWljJz5kxOP/10/v3vfzN48GCWLl1KRETEIe/19ttv87vf/Y7q6moSEhJ4+eWXGTBgAKWlpdxxxx2kpaUhIvzmN79hzpw5vP/++9x///3U1dWRmJjIxx9/zAMPPECfPn246667ABg3bhzvvPMOADNnzuTss8/miy++4K233uKRRx5h9erVVFRUcMUVV/Dggw8CsHr1au68807KysoICwvj448/5sILL+SJJ55g4sSJAJx22mk8/fTTjB8/vtOfgQUKV0P6DuujMKZ7eeSRR9iwYQNr164F4JNPPuHrr79mw4YNjUNBFyxYQHx8PBUVFUyZMoU5c+aQkJBwyHm2b9/Oq6++ynPPPcdVV13F66+/zvXXX3/IPqeffjpffvklIsLzzz/Po48+ymOPPcZDDz1EbGws69evB6CgoICcnBxuueUWVq1aRUpKCvn5+W1ey9atW3nhhRcaa0gPP/ww8fHx1NXVce655/Ldd98xatQorr76av7xj38wZcoUiouLiYiI4Oabb2bhwoU8/vjjbNu2jaqqqi4JEmCBolFjQkAb9WRMh7X2y/9Imjp16iHzBf73f/+XN998E4CMjAy2b99+WKBISUlp/DU+efJkdu3addh5MzMzufrqq9m3bx/V1dWN7/HRRx+xaNGixv3i4uJ4++23OfPMMxv3iY+Pb7Pcw4YN4+STT25cXrx4MfPnz6e2tpZ9+/axadMmRISBAwcyZcoUAGJiYgC48soreeihh5g3bx4LFizgxhtvbPP9fGV9FK6DKcatRmFMdxcVFdX4+pNPPuGjjz7iiy++YN26dUyaNKnZ+QRhYQd/JHo8Hmpraw/b54477uD2229n/fr1PPvss43nUdXDhp82tw4gODj4kP4H77J4l3vnzp388Y9/5OOPP+a7777joosuorKyssXzRkZGMn36dJYuXcrixYu57rrrmv3bdIQFCldeaRXhIUFEhnoCXRRjTDtER0dTUlLS4vaioiLi4uKIjIxky5YtfPnllx1+r6KiIgYPdu6W8Le//a1x/fnnn8+TTz7ZuFxQUMApp5zCp59+ys6dOwEam56Sk5P55ptvAPjmm28atzdVXFxMVFQUsbGxHDhwgPfeew+AUaNGkZWVxerVqwEoKSlpDGo333wzP/vZz5gyZYpPNRhfWaBw5ZU6k+1s4pAx3UtCQgKnnXYa48aN4+677z5s+4wZM6itrWX8+PH86le/OqRpp70eeOABrrzySs444wwSExMb1//yl7+koKCAcePGMWHCBFauXEm/fv2YP38+l19+ORMmTODqq68GYM6cOeTn5zNx4kSefvppRo4c2ex7TZgwgUmTJjF27Fh+/OMfc9pppwEQGhrKP/7xD+644w4mTJjA9OnTG2slkydPJiYmhptuuqnD19gcUe3ULRyOKqmpqZqW1rHba9+w4GuKKmpY+tPTurhUxvRsmzdvZvTo0YEuhgGysrKYNm0aW7ZsISjo8HpAc5+ViKxR1dTWzms1CldeaRWJNofCGNNNvfjii5x00kk8/PDDzQaJzrBRT6680mrGDooJdDGMMaZDbrjhBm644Ya2d+wAq1HgpuAtq7LJdsYY0wwLFEBxRS01dWrpO4wxphl+DRQiMkNEtorIDhG5t4V9ponIWhHZKCKftufYrpJb5k62sxqFMcYcxm99FCLiAZ4CpgOZwGoRWaaqm7z26Qv8FZihqntEpL+vx3YlS99hjDEt82eNYiqwQ1XTVbUaWATMbrLPdcAbqroHQFWz23Fsl2lMCGjpO4zpdjqTZhzg8ccfp7y8vAtL1PP4M1AMBjK8ljPddd5GAnEi8omIrBGRG9pxLAAiMldE0kQkLScnp0MFzXXTd9j9so3pfnpCoGguXcjRxJ/DY5ub4tx0dl8wMBk4F4gAvhCRL3081lmpOh+YD86Eu44UtKFGEWed2cZ0znv3wv71XXvOY06AmY+0uLlpmvF58+Yxb948Fi9eTFVVFZdddhkPPvggZWVlXHXVVWRmZlJXV8evfvUrDhw4QFZWFmeffTaJiYmsXLnykHP/9re/5e2336aiooJTTz2VZ599FhFhx44d3HbbbeTk5ODxeFiyZAnHHnssjz76KC+99BJBQUHMnDmTRx55hGnTpvHHP/6R1NRUcnNzSU1NZdeuXSxcuJB3332XyspKysrKWLZsGbNnz6agoICamhp+97vfMXu205Dy4osv8sc//hERYfz48fz1r39l/PjxbNu2jZCQEIqLixk/fjzbt28nJCSka//++DdQZAJDvJaTgKxm9slV1TKgTERWARN8PLbL5JVW0zcyhBCPDQIzprtpmmZ8xYoVbN++na+//hpV5ZJLLmHVqlXk5OQwaNAg3n33XcDJ2xQbG8uf/vQnVq5ceUhKjga33347v/71rwH44Q9/yDvvvMOsWbP4wQ9+wL333stll11GZWUl9fX1vPfee7z11lt89dVXREZG+pRW/IsvvuC7774jPj6e2tpa3nzzTWJiYsjNzeXkk0/mkksuYdOmTTz88MN8/vnnJCYmkp+fT3R0NNOmTePdd9/l0ksvZdGiRcyZM8cvQQL8GyhWA8eJSAqwF7gGp0/C21LgSREJBkKBk4A/A1t8OLbL5JVV2dBYY7pCK7/8j5QVK1awYsUKJk2aBEBpaSnbt2/njDPO4K677uKee+7h4osv5owzzmjzXCtXruTRRx+lvLyc/Px8xo4dy7Rp09i7dy+XXXYZAOHh4YCTavymm24iMjIS8C2t+PTp0xv3U1Xuv/9+Vq1aRVBQEHv37uXAgQP885//5IorrmgMZA3733zzzTz66KNceumlvPDCCzz33HPt/Ev5zm+BQlVrReR24APAAyxQ1Y0icpu7/RlV3Swi7wPfAfXA86q6AaC5Y/1V1tzSaptsZ0wPoarcd9993HrrrYdtW7NmDcuXL+e+++7j/PPPb6wtNKeyspL/+I//IC0tjSFDhvDAAw80pvlu6X3bSiveNL25d1rxl19+mZycHNasWUNISAjJycmtphU/7bTT2LVrF59++il1dXWMGzeuxWvpLL+2tajqclUdqarHqurD7rpnVPUZr33mqeoYVR2nqo+3dqy/5JVWWUe2Md1U0zTjF1xwAQsWLKC0tBSAvXv3kp2dTVZWFpGRkVx//fXcddddjam+W0pT3vClnpiYSGlpKa+99hrg3CgoKSmJt956C4CqqirKy8s5//zzWbBgQWPHuHda8TVr1gA0nqM5RUVF9O/fn5CQEFauXMnu3bsBOPfcc1m8eDF5eXmHnBectB3XXnttl2eLbcpyPeHctMiGxhrTPXmnGZ85cybz5s1j8+bNnHLKKQD06dOHv//97+zYsYO7776boKAgQkJCePrppwGYO3cuM2fOZODAgYd0Zvft25dbbrmFE044geTk5MY7ygG89NJL3Hrrrfz6178mJCSEJUuWMGPGDNauXUtqaiqhoaFceOGF/P73v+euu+7iqquu4qWXXuKcc85p8Tp+8IMfMGvWLFJTU5k4cSKjRo0CYOzYsfzP//wPZ511Fh6Ph0mTJrFw4cLGY375y19y7bXXdvWf9RC9Ps24qvKLxes4c2Qil01K8lPJjOm5LM144Lz22mssXbqUl156yaf9O5pmvNfXKESEP189MdDFMMaYdrnjjjt47733WL58ud/fq9cHCmOM6Y6eeOKJI/ZeNnHAGNNpPakJu6fqzGdkgcIY0ynh4eHk5eVZsDiKqSp5eXmNcz7ay5qejDGdkpSURGZmJh3NtWaOjPDwcJKSOjZgxwKFMaZTQkJCSElJCXQxjB9Z05MxxphWWaAwxhjTKgsUxhhjWtWjZmaLSA6wu4OHJwK5XVicQOtp1wM975p62vVAz7umnnY9cPg1DVPVfq0d0KMCRWeISFpb09i7k552PdDzrqmnXQ/0vGvqadcDHbsma3oyxhjTKgsUxhhjWmWB4qD5gS5AF+tp1wM975p62vVAz7umnnY90IFrsj4KY4wxrbIahTHGmFZZoDDGGNOqXh8oRGSGiGwVkR0icm+gy9MVRGSXiKwXkbUi0r5b/h0FRGSBiGSLyAavdfEi8qGIbHef4wJZxvZq4ZoeEJG97ue0VkQuDGQZ20NEhojIShHZLCIbReROd323/ZxauaZu+TmJSLiIfC0i69zredBd3+7PqFf3UYiIB9gGTAcygdXAtaq6KaAF6yQR2QWkqmq3nCgkImcCpcCLqjrOXfcokK+qj7gBPU5V7wlkOdujhWt6AChV1T8GsmwdISIDgYGq+o2IRANrgEuBG+mmn1Mr13QV3fBzEhEBolS1VERCgM+AO4HLaedn1NtrFFOBHaqarqrVwCJgdoDL1Oup6iogv8nq2cDf3Nd/w/kP3G20cE3dlqruU9Vv3NclwGZgMN34c2rlmroldZS6iyHuQ+nAZ9TbA8VgIMNrOZNu/A/DiwIrRGSNiMwNdGG6yABV3QfOf2igf4DL01VuF5Hv3KapbtNM401EkoFJwFf0kM+pyTVBN/2cRMQjImuBbOBDVe3QZ9TbA4U0s64ntMWdpqonAjOBn7rNHubo8zRwLDAR2Ac8FtDSdICI9AFeB/5TVYsDXZ6u0Mw1ddvPSVXrVHUikARMFZFxHTlPbw8UmcAQr+UkICtAZekyqprlPmcDb+I0sXV3B9w25Ia25OwAl6fTVPWA+x+5HniObvY5ue3erwMvq+ob7upu/Tk1d03d/XMCUNVC4BNgBh34jHp7oFgNHCciKSISClwDLAtwmTpFRKLcjjhEJAo4H9jQ+lHdwjLgR+7rHwFLA1iWLtHwn9V1Gd3oc3I7Sv8fsFlV/+S1qdt+Ti1dU3f9nESkn4j0dV9HAOcBW+jAZ9SrRz0BuEPdHgc8wAJVfTiwJeocERmOU4sA51a3r3S3axKRV4FpOOmQDwC/Ad4CFgNDgT3AlarabTqHW7imaTjNGQrsAm5taDs+2onI6cC/gPVAvbv6fpw2/W75ObVyTdfSDT8nERmP01ntwakULFbV34pIAu38jHp9oDDGGNO63t70ZIwxpg0WKIwxxrTKAoUxxphWWaAwxhjTKgsUxhhjWmWBwhhjTKssUBhjjGnV/wcApAG+5ttwyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plot_history(history)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "Test_data_accurasy_Predict"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.1422 - accuracy: 0.9438\n",
      "\n",
      "Test accuracy: 0.9437500238418579\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "Check_prediction"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Predicted label: [0]\n"
     ]
    }
   ],
   "source": [
    "    X_to_predict = X_test[30]\n",
    "    y_to_predict = y_test[30]\n",
    "\n",
    "    predict(model, X_to_predict, y_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "Test_audio_convert_MFCC_and_predict"
    ]
   },
   "outputs": [],
   "source": [
    "def test_data_analyze(file_path):\n",
    "    data = {\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "    num_mfcc=13\n",
    "    n_fft=2048\n",
    "    hop_length=512\n",
    "    num_segments=1\n",
    "    c = 0\n",
    "    k = 0\n",
    "    \n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "    signal, sample_rate = librosa.load(file_path,sr=SAMPLE_RATE)\n",
    "    if len(signal) >= SAMPLE_RATE:\n",
    "        signals = signal\n",
    "    else:\n",
    "        signal = np.pad(\n",
    "            signal,\n",
    "            pad_width=(SAMPLE_RATE - len(signal), 0),\n",
    "            mode=\"constant\",\n",
    "            constant_values=(0, 0),\n",
    "        )\n",
    "    start = samples_per_segment \n",
    "    finish = start + samples_per_segment\n",
    "    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "        data[\"mfcc\"].append(mfcc.tolist())\n",
    "    with open(json_path1, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "    with open(json_path1, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    X = X[..., np.newaxis]\n",
    "    y = X[0]\n",
    "    y = y[np.newaxis, ...]\n",
    "\n",
    "    prediction = model.predict(y)\n",
    "\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    #print(file_path)\n",
    "    #print(predicted_index)\n",
    "    return predicted_index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "Fuction_to_open_File_directroy"
    ]
   },
   "outputs": [],
   "source": [
    "def vvvv():\n",
    "    l=0\n",
    "    h=0\n",
    "    dataset_path='test'\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)): \n",
    "        for f in filenames: \n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            z=test_data_analyze(file_path)\n",
    "            print(\" target={} predicted_index= {} number={} \".format((h-1), z,h))\n",
    "            if z == h-1:\n",
    "                #print(\" target={} predicted_index= {} number={} \".format((h-1), z,h))\n",
    "                l = l + 1\n",
    "        h += 1\n",
    "        print(\" ************target={}  \".format(l))\n",
    "    print(\"Test_data_accurasy={}\".format(l/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "Call_the_Function"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ************target=0  \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [0] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [1] number=1 \n",
      " target=0 predicted_index= [2] number=1 \n",
      " ************target=50  \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " target=1 predicted_index= [2] number=2 \n",
      " target=1 predicted_index= [1] number=2 \n",
      " ************target=121  \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [1] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " target=2 predicted_index= [2] number=3 \n",
      " ************target=209  \n",
      "Test_data_accurasy=69.66666666666667\n"
     ]
    }
   ],
   "source": [
    "vvvv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
